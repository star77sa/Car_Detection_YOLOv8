{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjH90uY3Cd0E"
      },
      "source": [
        "[![Roboflow Notebooks](https://ik.imagekit.io/roboflow/notebooks/template/bannertest2-2.png?ik-sdk-version=javascript-1.4.3&updatedAt=1672932710194)](https://github.com/roboflow/notebooks)\n",
        "\n",
        "# How to Use PolygonZone and Roboflow Supervision\n",
        "\n",
        "In this notebook, you will use [PolygonZone](https://roboflow.github.io/polygonzone/) with [Roboflow Supervision](https://roboflow.com/supervision) to draw polygons on a video frame. These polygons will be used as zones in which predictions will be grouped.\n",
        "\n",
        "This notebook accompanies the \"Calculate Polygon Coordinates with PolygonZone\" tutorial on the Roboflow blog.\n",
        "\n",
        "## Pro Tip: Use GPU Acceleration\n",
        "\n",
        "If you are running this notebook in Google Colab, navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator`, set it to `GPU`, and then click `Save`. This will ensure your notebook uses a GPU, which will significantly speed up model training times.\n",
        "\n",
        "## Steps in this Tutorial\n",
        "\n",
        "In this guide, we will:\n",
        "\n",
        "1. Install supervision and YOLOv8.\n",
        "2. Prepare polygon zones for a traffic video.\n",
        "3. Run inference on a traffic video.\n",
        "4. Save the results of inference to a file.\n",
        "\n",
        "**Let's begin!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2021 NVIDIA Corporation\n",
            "Built on Sun_Mar_21_19:15:46_PDT_2021\n",
            "Cuda compilation tools, release 11.3, V11.3.58\n",
            "Build cuda_11.3.r11.3/compiler.29745058_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting package metadata (current_repodata.json): done\n",
            "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
            "Collecting package metadata (repodata.json): done\n",
            "Solving environment: done\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "  current version: 22.9.0\n",
            "  latest version: 23.3.1\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c defaults conda\n",
            "\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /home/ksko/.conda/envs/yolo8\n",
            "\n",
            "  added / updated specs:\n",
            "    - cudatoolkit=11.3\n",
            "    - pytorch==1.12.1\n",
            "    - torchaudio==0.12.1\n",
            "    - torchvision==0.13.1\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    brotlipy-0.7.0             |py37h27cfd23_1003         320 KB\n",
            "    cffi-1.15.1                |   py37h5eee18b_3         240 KB\n",
            "    cryptography-39.0.1        |   py37h9ce1e76_0         1.4 MB\n",
            "    giflib-5.2.1               |       h5eee18b_3          80 KB\n",
            "    idna-3.4                   |   py37h06a4308_0          91 KB\n",
            "    jpeg-9e                    |       h5eee18b_1         262 KB\n",
            "    libdeflate-1.17            |       h5eee18b_0          69 KB\n",
            "    libpng-1.6.39              |       h5eee18b_0         304 KB\n",
            "    libtasn1-4.19.0            |       h5eee18b_0          63 KB\n",
            "    libtiff-4.5.0              |       h6a678d5_2         479 KB\n",
            "    libwebp-1.2.4              |       h11a3e52_1          86 KB\n",
            "    libwebp-base-1.2.4         |       h5eee18b_1         376 KB\n",
            "    mkl-service-2.4.0          |   py37h7f8727e_0          56 KB\n",
            "    mkl_fft-1.3.1              |   py37hd3c417c_0         172 KB\n",
            "    mkl_random-1.2.2           |   py37h51133e4_0         287 KB\n",
            "    numpy-1.21.5               |   py37h6c91a56_3          10 KB\n",
            "    numpy-base-1.21.5          |   py37ha15fc14_3         4.8 MB\n",
            "    pillow-9.4.0               |   py37h6a678d5_0         721 KB\n",
            "    pyopenssl-23.0.0           |   py37h06a4308_0          96 KB\n",
            "    pysocks-1.7.1              |           py37_1          27 KB\n",
            "    pytorch-1.12.1             |py3.7_cuda11.3_cudnn8.3.2_0        1.19 GB  pytorch\n",
            "    requests-2.28.1            |   py37h06a4308_0          92 KB\n",
            "    torchaudio-0.12.1          |       py37_cu113         6.2 MB  pytorch\n",
            "    torchvision-0.13.1         |       py37_cu113        28.6 MB  pytorch\n",
            "    typing_extensions-4.3.0    |   py37h06a4308_0          42 KB\n",
            "    urllib3-1.26.14            |   py37h06a4308_0         195 KB\n",
            "    zstd-1.5.5                 |       hc292b87_0         647 KB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        1.24 GB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  blas               pkgs/main/linux-64::blas-1.0-mkl None\n",
            "  brotlipy           pkgs/main/linux-64::brotlipy-0.7.0-py37h27cfd23_1003 None\n",
            "  bzip2              pkgs/main/linux-64::bzip2-1.0.8-h7b6447c_0 None\n",
            "  cffi               pkgs/main/linux-64::cffi-1.15.1-py37h5eee18b_3 None\n",
            "  charset-normalizer pkgs/main/noarch::charset-normalizer-2.0.4-pyhd3eb1b0_0 None\n",
            "  cryptography       pkgs/main/linux-64::cryptography-39.0.1-py37h9ce1e76_0 None\n",
            "  cudatoolkit        pkgs/main/linux-64::cudatoolkit-11.3.1-h2bc3f7f_2 None\n",
            "  ffmpeg             pytorch/linux-64::ffmpeg-4.3-hf484d3e_0 None\n",
            "  freetype           pkgs/main/linux-64::freetype-2.12.1-h4a9f257_0 None\n",
            "  giflib             pkgs/main/linux-64::giflib-5.2.1-h5eee18b_3 None\n",
            "  gmp                pkgs/main/linux-64::gmp-6.2.1-h295c915_3 None\n",
            "  gnutls             pkgs/main/linux-64::gnutls-3.6.15-he1e5248_0 None\n",
            "  idna               pkgs/main/linux-64::idna-3.4-py37h06a4308_0 None\n",
            "  intel-openmp       pkgs/main/linux-64::intel-openmp-2021.4.0-h06a4308_3561 None\n",
            "  jpeg               pkgs/main/linux-64::jpeg-9e-h5eee18b_1 None\n",
            "  lame               pkgs/main/linux-64::lame-3.100-h7b6447c_0 None\n",
            "  lcms2              pkgs/main/linux-64::lcms2-2.12-h3be6417_0 None\n",
            "  lerc               pkgs/main/linux-64::lerc-3.0-h295c915_0 None\n",
            "  libdeflate         pkgs/main/linux-64::libdeflate-1.17-h5eee18b_0 None\n",
            "  libiconv           pkgs/main/linux-64::libiconv-1.16-h7f8727e_2 None\n",
            "  libidn2            pkgs/main/linux-64::libidn2-2.3.2-h7f8727e_0 None\n",
            "  libpng             pkgs/main/linux-64::libpng-1.6.39-h5eee18b_0 None\n",
            "  libtasn1           pkgs/main/linux-64::libtasn1-4.19.0-h5eee18b_0 None\n",
            "  libtiff            pkgs/main/linux-64::libtiff-4.5.0-h6a678d5_2 None\n",
            "  libunistring       pkgs/main/linux-64::libunistring-0.9.10-h27cfd23_0 None\n",
            "  libwebp            pkgs/main/linux-64::libwebp-1.2.4-h11a3e52_1 None\n",
            "  libwebp-base       pkgs/main/linux-64::libwebp-base-1.2.4-h5eee18b_1 None\n",
            "  lz4-c              pkgs/main/linux-64::lz4-c-1.9.4-h6a678d5_0 None\n",
            "  mkl                pkgs/main/linux-64::mkl-2021.4.0-h06a4308_640 None\n",
            "  mkl-service        pkgs/main/linux-64::mkl-service-2.4.0-py37h7f8727e_0 None\n",
            "  mkl_fft            pkgs/main/linux-64::mkl_fft-1.3.1-py37hd3c417c_0 None\n",
            "  mkl_random         pkgs/main/linux-64::mkl_random-1.2.2-py37h51133e4_0 None\n",
            "  nettle             pkgs/main/linux-64::nettle-3.7.3-hbbd107a_1 None\n",
            "  numpy              pkgs/main/linux-64::numpy-1.21.5-py37h6c91a56_3 None\n",
            "  numpy-base         pkgs/main/linux-64::numpy-base-1.21.5-py37ha15fc14_3 None\n",
            "  openh264           pkgs/main/linux-64::openh264-2.1.1-h4ff587b_0 None\n",
            "  pillow             pkgs/main/linux-64::pillow-9.4.0-py37h6a678d5_0 None\n",
            "  pycparser          pkgs/main/noarch::pycparser-2.21-pyhd3eb1b0_0 None\n",
            "  pyopenssl          pkgs/main/linux-64::pyopenssl-23.0.0-py37h06a4308_0 None\n",
            "  pysocks            pkgs/main/linux-64::pysocks-1.7.1-py37_1 None\n",
            "  pytorch            pytorch/linux-64::pytorch-1.12.1-py3.7_cuda11.3_cudnn8.3.2_0 None\n",
            "  pytorch-mutex      pytorch/noarch::pytorch-mutex-1.0-cuda None\n",
            "  requests           pkgs/main/linux-64::requests-2.28.1-py37h06a4308_0 None\n",
            "  six                pkgs/main/noarch::six-1.16.0-pyhd3eb1b0_1 None\n",
            "  torchaudio         pytorch/linux-64::torchaudio-0.12.1-py37_cu113 None\n",
            "  torchvision        pytorch/linux-64::torchvision-0.13.1-py37_cu113 None\n",
            "  typing_extensions  pkgs/main/linux-64::typing_extensions-4.3.0-py37h06a4308_0 None\n",
            "  urllib3            pkgs/main/linux-64::urllib3-1.26.14-py37h06a4308_0 None\n",
            "  zstd               pkgs/main/linux-64::zstd-1.5.5-hc292b87_0 None\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "pytorch-1.12.1       | 1.19 GB   | ##################################### | 100% \n",
            "idna-3.4             | 91 KB     | ##################################### | 100% \n",
            "numpy-1.21.5         | 10 KB     | ##################################### | 100% \n",
            "pillow-9.4.0         | 721 KB    | ##################################### | 100% \n",
            "zstd-1.5.5           | 647 KB    | ##################################### | 100% \n",
            "requests-2.28.1      | 92 KB     | ##################################### | 100% \n",
            "pysocks-1.7.1        | 27 KB     | ##################################### | 100% \n",
            "torchvision-0.13.1   | 28.6 MB   | ##################################### | 100% \n",
            "libdeflate-1.17      | 69 KB     | ##################################### | 100% \n",
            "pyopenssl-23.0.0     | 96 KB     | ##################################### | 100% \n",
            "mkl_fft-1.3.1        | 172 KB    | ##################################### | 100% \n",
            "typing_extensions-4. | 42 KB     | ##################################### | 100% \n",
            "libwebp-base-1.2.4   | 376 KB    | ##################################### | 100% \n",
            "libpng-1.6.39        | 304 KB    | ##################################### | 100% \n",
            "urllib3-1.26.14      | 195 KB    | ##################################### | 100% \n",
            "jpeg-9e              | 262 KB    | ##################################### | 100% \n",
            "libwebp-1.2.4        | 86 KB     | ##################################### | 100% \n",
            "cffi-1.15.1          | 240 KB    | ##################################### | 100% \n",
            "brotlipy-0.7.0       | 320 KB    | ##################################### | 100% \n",
            "mkl-service-2.4.0    | 56 KB     | ##################################### | 100% \n",
            "mkl_random-1.2.2     | 287 KB    | ##################################### | 100% \n",
            "libtasn1-4.19.0      | 63 KB     | ##################################### | 100% \n",
            "numpy-base-1.21.5    | 4.8 MB    | ##################################### | 100% \n",
            "torchaudio-0.12.1    | 6.2 MB    | ##################################### | 100% \n",
            "giflib-5.2.1         | 80 KB     | ##################################### | 100% \n",
            "cryptography-39.0.1  | 1.4 MB    | ##################################### | 100% \n",
            "libtiff-4.5.0        | 479 KB    | ##################################### | 100% \n",
            "Preparing transaction: done\n",
            "Verifying transaction: done\n",
            "Executing transaction: \\ By downloading and using the CUDA Toolkit conda packages, you accept the terms and conditions of the CUDA End User License Agreement (EULA): https://docs.nvidia.com/cuda/eula/index.html\n",
            "\n",
            "done\n",
            "Retrieving notices: ...working... done\n",
            "\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "conda install pytorch==1.12.1 torchvision==0.13.1 torchaudio==0.12.1 cudatoolkit=11.3 -c pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num gpu: 2\n"
          ]
        }
      ],
      "source": [
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6, 7\"\n",
        "n_gpu = torch.cuda.device_count()\n",
        "print(\"num gpu:\", n_gpu)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOY6fEpqHozP"
      },
      "source": [
        "## Install Dependencies and Retrieve Video\n",
        "\n",
        "Install the required dependencies for this project. We'll be using Ultralytics' YOLOv8 model for inference, and Supervision for drawing our polygons and calculating how many objects appear in each annotated zone."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhblEdYHCZ3R",
        "outputId": "6b076619-8729-479f-9b5e-9d3bcec41ba2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: chardet in /home/ksko/.conda/envs/yolo8/lib/python3.7/site-packages (5.1.0)\n",
            "Collecting charset-normalizer==2.1.0\n",
            "  Downloading charset_normalizer-2.1.0-py3-none-any.whl (39 kB)\n",
            "Installing collected packages: charset-normalizer\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 3.1.0\n",
            "    Uninstalling charset-normalizer-3.1.0:\n",
            "      Successfully uninstalled charset-normalizer-3.1.0\n",
            "Successfully installed charset-normalizer-2.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install supervision --quiet\n",
        "!pip install ultralytics --quiet\n",
        "!pip install chardet\n",
        "!pip install charset-normalizer==2.1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjeceeFOPvwl",
        "outputId": "c80abe6e-24e3-4abf-bf89-eb6b38354021"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-04-16 08:17:41--  https://docs.google.com/uc?export=download&confirm=&id=1K15ijbTl78VSOPjfvGSgvqh7ME2U7cG2\n",
            "Resolving docs.google.com (docs.google.com)... 142.250.76.142, 2404:6800:400a:80e::200e\n",
            "Connecting to docs.google.com (docs.google.com)|142.250.76.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-0g-74-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/tgrik0vid3144j132j15tqa7q9tmc5al/1681633050000/03796184128890941253/*/1K15ijbTl78VSOPjfvGSgvqh7ME2U7cG2?e=download&uuid=552aad19-5d6f-4dc5-b31e-60442ca500bf [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2023-04-16 08:17:42--  https://doc-0g-74-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/tgrik0vid3144j132j15tqa7q9tmc5al/1681633050000/03796184128890941253/*/1K15ijbTl78VSOPjfvGSgvqh7ME2U7cG2?e=download&uuid=552aad19-5d6f-4dc5-b31e-60442ca500bf\n",
            "Resolving doc-0g-74-docs.googleusercontent.com (doc-0g-74-docs.googleusercontent.com)... 142.250.207.97, 2404:6800:400a:805::2001\n",
            "Connecting to doc-0g-74-docs.googleusercontent.com (doc-0g-74-docs.googleusercontent.com)|142.250.207.97|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 29782444 (28M) [video/mp4]\n",
            "Saving to: ‘video.mp4’\n",
            "\n",
            "video.mp4           100%[===================>]  28.40M  7.19MB/s    in 4.4s    \n",
            "\n",
            "2023-04-16 08:17:47 (6.50 MB/s) - ‘video.mp4’ saved [29782444/29782444]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1K15ijbTl78VSOPjfvGSgvqh7ME2U7cG2' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1K15ijbTl78VSOPjfvGSgvqh7ME2U7cG2\" -O video.mp4 && rm -rf /tmp/cookies.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4idu3fOHteH"
      },
      "source": [
        "## Initialize the Model and Video\n",
        "\n",
        "In the code snippet below, we import the required dependencies for our project, initialize a YOLOv8 model, and load a video into our project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "5684c82e404045109e27167ca4817eaf",
            "e526d9b1f45445268ddffd6fc3e8133a",
            "2aa4be84b8bc4a4bb59a626a81e2acdc",
            "d7fd42066585465a93f289f55504bbd2",
            "343a221a027c4a33b5e9c081bc81f7c2",
            "e3df80f7fe424d9ebeffeb3ec83780b6",
            "a45df22c143b49bb96b077f0797cee90",
            "e05518423ee14d34886fcbdc80f9bc4b",
            "5adc7616c0f14a27b299bc75a91acdb8",
            "d0d5858fae274036a20a98e5a401b7be",
            "d75030e954e54dec8be0773d54fef863"
          ]
        },
        "id": "p-IiJrLzCSX0",
        "outputId": "6e8fa511-a9d3-4021-a017-8f1e9a432094"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import supervision as sv\n",
        "import cv2\n",
        "\n",
        "from ultralytics import YOLO\n",
        "\n",
        "\n",
        "\n",
        "model = YOLO('yolov8s.pt')\n",
        "\n",
        "VIDEO = \"video.mp4\"\n",
        "\n",
        "video_info = sv.VideoInfo.from_video_path(VIDEO)\n",
        "colors = sv.ColorPalette.default()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YYn6nyEIAKW"
      },
      "source": [
        "## Save Frame\n",
        "\n",
        "The code snippet below saves the first frame in your video to a file called \"first_frame.png\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Xqe4WDHCXJa",
        "outputId": "172869b7-0c52-4c47-f8aa-438f86b9ec33"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# extract video frame\n",
        "generator = sv.get_video_frames_generator(VIDEO)\n",
        "iterator = iter(generator)\n",
        "\n",
        "frame = next(iterator)\n",
        "\n",
        "# save first frame\n",
        "cv2.imwrite(\"first_frame.png\", frame)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzOMO9ZLOpQv"
      },
      "source": [
        "Next, go to [PolygonZone](https://roboflow.github.io/polygonzone/) and draw polygons on your image. PolygonZone returns a list of polygon coordinates in both NumPy and JSON formats. Copy the NumPy output into the cell below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "pRDuOeUNOoHT"
      },
      "outputs": [],
      "source": [
        "polygons = [\n",
        "np.array([\n",
        "[718, 595],[927, 592],[851, 1062],[42, 1059]\n",
        "]),np.array([\n",
        "[987, 595],[1199, 595],[1893, 1056],[1015, 1062]\n",
        "])\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UgeoGfHIMS6"
      },
      "source": [
        "## Run Inference\n",
        "\n",
        "Using the YOLOv8 model we initialized earlier, as well as our Supervision objects, we can draw polygons on the first frame on our image and count the number of objects that appear.\n",
        "\n",
        "First, let's initialize our zones:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Xg29HwE1Odmb"
      },
      "outputs": [],
      "source": [
        "# initialize our zones\n",
        "\n",
        "zones = [\n",
        "    sv.PolygonZone(\n",
        "        polygon=polygon, \n",
        "        frame_resolution_wh=video_info.resolution_wh\n",
        "    )\n",
        "    for polygon\n",
        "    in polygons\n",
        "]\n",
        "zone_annotators = [\n",
        "    sv.PolygonZoneAnnotator(\n",
        "        zone=zone, \n",
        "        color=colors.by_idx(index), \n",
        "        thickness=4,\n",
        "        text_thickness=8,\n",
        "        text_scale=4\n",
        "    )\n",
        "    for index, zone\n",
        "    in enumerate(zones)\n",
        "]\n",
        "box_annotators = [\n",
        "    sv.BoxAnnotator(\n",
        "        color=colors.by_idx(index), \n",
        "        thickness=4, \n",
        "        text_thickness=4, \n",
        "        text_scale=2\n",
        "        )\n",
        "    for index\n",
        "    in range(len(polygons))\n",
        "]\n",
        "\n",
        "def process_frame(frame: np.ndarray, i) -> np.ndarray:\n",
        "    results = model(frame, imgsz=1280)[0]\n",
        "    detections = sv.Detections.from_yolov8(results)\n",
        "\n",
        "    for zone, zone_annotator, box_annotator in zip(zones, zone_annotators, box_annotators):\n",
        "        mask = zone.trigger(detections=detections)\n",
        "        detections_filtered = detections[mask]\n",
        "        frame = box_annotator.annotate(scene=frame, detections=detections_filtered, skip_label=True)\n",
        "        frame = zone_annotator.annotate(scene=frame)\n",
        "\n",
        "    return frame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9VBrt1SQPoX"
      },
      "source": [
        "Now we can run inference. Let's run inference on a single frame so we can make sure everything is working as expected:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "id": "lJ_CNArWILcg",
        "outputId": "33785f5b-e783-44f1-c0e5-a9ee8b7a9453"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 736x1280 23 cars, 2 buss, 3 trucks, 5 traffic lights, 10.0ms\n",
            "Speed: 0.9ms preprocess, 10.0ms inference, 1.1ms postprocess per image at shape (1, 3, 1280, 1280)\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "module 'supervision' has no attribute 'show_frame_in_notebook'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_1895512/2599483213.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzone_annotator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscene\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0msv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_frame_in_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: module 'supervision' has no attribute 'show_frame_in_notebook'"
          ]
        }
      ],
      "source": [
        "results = model(frame, imgsz=1280)[0]\n",
        "detections = sv.Detections.from_yolov8(results)\n",
        "\n",
        "for zone, zone_annotator, box_annotator in zip(zones, zone_annotators, box_annotators):\n",
        "    mask = zone.trigger(detections=detections)\n",
        "    detections_filtered = detections[mask]\n",
        "    frame = box_annotator.annotate(scene=frame, detections=detections_filtered)\n",
        "    frame = zone_annotator.annotate(scene=frame)\n",
        "\n",
        "sv.show_frame_in_notebook(frame, (16, 16))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python 3.8.16\n"
          ]
        }
      ],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FSjphrsQVLy"
      },
      "source": [
        "The frame above shows all of the predictions in the polygons we have drawn. Now we can proceed to run inference on the rest of the video."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNB4TmIyHNzK"
      },
      "source": [
        "## Video Inference\n",
        "\n",
        "Use the code snippet below to run inference on the video you specified earlier and save the results to \"result.mp4\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20DObemvCY8c",
        "outputId": "6c6f25d8-9ed3-4ccf-b784-03e8ca53e092"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 736x1280 34 cars, 2 buss, 6 trucks, 5 traffic lights, 30.6ms\n",
            "Speed: 1.1ms pre-process, 30.6ms inference, 2.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 30 cars, 2 buss, 7 trucks, 6 traffic lights, 30.5ms\n",
            "Speed: 1.0ms pre-process, 30.5ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 34 cars, 2 buss, 8 trucks, 6 traffic lights, 30.5ms\n",
            "Speed: 1.1ms pre-process, 30.5ms inference, 3.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 33 cars, 2 buss, 4 trucks, 6 traffic lights, 30.7ms\n",
            "Speed: 1.1ms pre-process, 30.7ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 34 cars, 2 buss, 6 trucks, 7 traffic lights, 30.8ms\n",
            "Speed: 1.1ms pre-process, 30.8ms inference, 2.3ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 33 cars, 2 buss, 6 trucks, 5 traffic lights, 30.7ms\n",
            "Speed: 1.1ms pre-process, 30.7ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 33 cars, 2 buss, 7 trucks, 6 traffic lights, 27.0ms\n",
            "Speed: 1.0ms pre-process, 27.0ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 37 cars, 3 buss, 5 trucks, 6 traffic lights, 26.9ms\n",
            "Speed: 1.0ms pre-process, 26.9ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 32 cars, 2 buss, 6 trucks, 6 traffic lights, 27.1ms\n",
            "Speed: 1.0ms pre-process, 27.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 36 cars, 2 buss, 8 trucks, 7 traffic lights, 26.4ms\n",
            "Speed: 1.0ms pre-process, 26.4ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 38 cars, 2 buss, 7 trucks, 7 traffic lights, 26.3ms\n",
            "Speed: 1.1ms pre-process, 26.3ms inference, 2.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 33 cars, 2 buss, 6 trucks, 6 traffic lights, 26.5ms\n",
            "Speed: 1.2ms pre-process, 26.5ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 35 cars, 2 buss, 4 trucks, 8 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 37 cars, 2 buss, 4 trucks, 8 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 36 cars, 2 buss, 6 trucks, 7 traffic lights, 28.8ms\n",
            "Speed: 1.1ms pre-process, 28.8ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 35 cars, 2 buss, 6 trucks, 6 traffic lights, 26.0ms\n",
            "Speed: 1.1ms pre-process, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 35 cars, 2 buss, 6 trucks, 7 traffic lights, 25.9ms\n",
            "Speed: 1.1ms pre-process, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 36 cars, 2 buss, 7 trucks, 7 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 3.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 37 cars, 2 buss, 6 trucks, 7 traffic lights, 28.3ms\n",
            "Speed: 2.9ms pre-process, 28.3ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 39 cars, 2 buss, 7 trucks, 8 traffic lights, 26.0ms\n",
            "Speed: 1.1ms pre-process, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 37 cars, 2 buss, 7 trucks, 8 traffic lights, 26.0ms\n",
            "Speed: 1.1ms pre-process, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 2 buss, 6 trucks, 8 traffic lights, 26.0ms\n",
            "Speed: 1.1ms pre-process, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 2 buss, 6 trucks, 8 traffic lights, 26.0ms\n",
            "Speed: 1.1ms pre-process, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 38 cars, 4 buss, 7 trucks, 8 traffic lights, 25.9ms\n",
            "Speed: 0.9ms pre-process, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 35 cars, 4 buss, 7 trucks, 8 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 33 cars, 2 buss, 7 trucks, 6 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 35 cars, 2 buss, 6 trucks, 6 traffic lights, 25.9ms\n",
            "Speed: 1.1ms pre-process, 25.9ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 30 cars, 2 buss, 8 trucks, 7 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 28 cars, 2 buss, 8 trucks, 6 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 31 cars, 2 buss, 8 trucks, 6 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 31 cars, 3 buss, 8 trucks, 5 traffic lights, 26.0ms\n",
            "Speed: 1.1ms pre-process, 26.0ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 34 cars, 3 buss, 7 trucks, 5 traffic lights, 26.4ms\n",
            "Speed: 1.0ms pre-process, 26.4ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 33 cars, 2 buss, 7 trucks, 5 traffic lights, 26.2ms\n",
            "Speed: 1.0ms pre-process, 26.2ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 33 cars, 2 buss, 6 trucks, 5 traffic lights, 26.0ms\n",
            "Speed: 1.0ms pre-process, 26.0ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 34 cars, 2 buss, 6 trucks, 5 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 35 cars, 2 buss, 7 trucks, 5 traffic lights, 26.3ms\n",
            "Speed: 1.0ms pre-process, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 39 cars, 2 buss, 8 trucks, 5 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 35 cars, 2 buss, 7 trucks, 6 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 36 cars, 2 buss, 7 trucks, 6 traffic lights, 26.2ms\n",
            "Speed: 1.0ms pre-process, 26.2ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 39 cars, 2 buss, 6 trucks, 4 traffic lights, 26.2ms\n",
            "Speed: 1.1ms pre-process, 26.2ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 2 buss, 6 trucks, 5 traffic lights, 1 refrigerator, 26.0ms\n",
            "Speed: 1.1ms pre-process, 26.0ms inference, 2.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 37 cars, 2 buss, 9 trucks, 6 traffic lights, 26.5ms\n",
            "Speed: 1.1ms pre-process, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 39 cars, 3 buss, 8 trucks, 6 traffic lights, 26.4ms\n",
            "Speed: 1.1ms pre-process, 26.4ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 38 cars, 2 buss, 8 trucks, 7 traffic lights, 26.4ms\n",
            "Speed: 1.1ms pre-process, 26.4ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 2 buss, 6 trucks, 6 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 4.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 2 buss, 7 trucks, 5 traffic lights, 28.9ms\n",
            "Speed: 1.1ms pre-process, 28.9ms inference, 2.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 2 buss, 7 trucks, 6 traffic lights, 28.5ms\n",
            "Speed: 1.1ms pre-process, 28.5ms inference, 4.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 2 buss, 8 trucks, 6 traffic lights, 26.3ms\n",
            "Speed: 1.1ms pre-process, 26.3ms inference, 2.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 2 buss, 7 trucks, 5 traffic lights, 26.0ms\n",
            "Speed: 1.1ms pre-process, 26.0ms inference, 5.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 2 buss, 7 trucks, 6 traffic lights, 26.0ms\n",
            "Speed: 1.1ms pre-process, 26.0ms inference, 2.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 2 buss, 6 trucks, 6 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 2 buss, 7 trucks, 6 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 2 buss, 6 trucks, 6 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 2 buss, 5 trucks, 6 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 2 buss, 6 trucks, 6 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 50 cars, 2 buss, 7 trucks, 6 traffic lights, 26.4ms\n",
            "Speed: 1.0ms pre-process, 26.4ms inference, 2.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 2 buss, 4 trucks, 6 traffic lights, 26.0ms\n",
            "Speed: 1.0ms pre-process, 26.0ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 2 buss, 4 trucks, 6 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 37 cars, 2 buss, 6 trucks, 5 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 39 cars, 2 buss, 5 trucks, 5 traffic lights, 26.0ms\n",
            "Speed: 1.0ms pre-process, 26.0ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 39 cars, 2 buss, 4 trucks, 5 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 2 buss, 4 trucks, 4 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 1 bus, 7 trucks, 4 traffic lights, 26.0ms\n",
            "Speed: 0.9ms pre-process, 26.0ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 1 bus, 5 trucks, 6 traffic lights, 26.1ms\n",
            "Speed: 1.0ms pre-process, 26.1ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 2 buss, 7 trucks, 6 traffic lights, 26.1ms\n",
            "Speed: 1.0ms pre-process, 26.1ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 38 cars, 2 buss, 6 trucks, 6 traffic lights, 27.2ms\n",
            "Speed: 1.0ms pre-process, 27.2ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 37 cars, 2 buss, 5 trucks, 5 traffic lights, 27.3ms\n",
            "Speed: 9.4ms pre-process, 27.3ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 3 buss, 4 trucks, 7 traffic lights, 30.5ms\n",
            "Speed: 1.0ms pre-process, 30.5ms inference, 2.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 3 buss, 6 trucks, 7 traffic lights, 27.7ms\n",
            "Speed: 1.0ms pre-process, 27.7ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 2 buss, 5 trucks, 7 traffic lights, 30.2ms\n",
            "Speed: 1.0ms pre-process, 30.2ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 48 cars, 3 buss, 5 trucks, 7 traffic lights, 28.3ms\n",
            "Speed: 1.1ms pre-process, 28.3ms inference, 2.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 2 buss, 5 trucks, 6 traffic lights, 28.8ms\n",
            "Speed: 1.0ms pre-process, 28.8ms inference, 2.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 2 buss, 5 trucks, 7 traffic lights, 28.8ms\n",
            "Speed: 1.0ms pre-process, 28.8ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 2 buss, 4 trucks, 7 traffic lights, 29.4ms\n",
            "Speed: 1.1ms pre-process, 29.4ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 3 buss, 7 trucks, 6 traffic lights, 29.3ms\n",
            "Speed: 1.0ms pre-process, 29.3ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 49 cars, 2 buss, 8 trucks, 6 traffic lights, 29.9ms\n",
            "Speed: 1.0ms pre-process, 29.9ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 48 cars, 2 buss, 7 trucks, 6 traffic lights, 29.9ms\n",
            "Speed: 1.1ms pre-process, 29.9ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 2 buss, 9 trucks, 6 traffic lights, 30.4ms\n",
            "Speed: 1.0ms pre-process, 30.4ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 2 buss, 10 trucks, 7 traffic lights, 33.0ms\n",
            "Speed: 1.0ms pre-process, 33.0ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 2 buss, 10 trucks, 7 traffic lights, 36.0ms\n",
            "Speed: 1.0ms pre-process, 36.0ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 2 buss, 8 trucks, 6 traffic lights, 30.5ms\n",
            "Speed: 1.1ms pre-process, 30.5ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 2 buss, 9 trucks, 8 traffic lights, 30.5ms\n",
            "Speed: 1.0ms pre-process, 30.5ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 2 buss, 13 trucks, 8 traffic lights, 30.6ms\n",
            "Speed: 1.1ms pre-process, 30.6ms inference, 2.1ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 2 buss, 10 trucks, 6 traffic lights, 30.5ms\n",
            "Speed: 1.1ms pre-process, 30.5ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 2 buss, 12 trucks, 7 traffic lights, 30.5ms\n",
            "Speed: 1.0ms pre-process, 30.5ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 39 cars, 2 buss, 10 trucks, 6 traffic lights, 35.4ms\n",
            "Speed: 1.0ms pre-process, 35.4ms inference, 2.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 38 cars, 2 buss, 11 trucks, 6 traffic lights, 32.5ms\n",
            "Speed: 1.1ms pre-process, 32.5ms inference, 2.1ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 2 buss, 12 trucks, 7 traffic lights, 30.6ms\n",
            "Speed: 1.0ms pre-process, 30.6ms inference, 2.3ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 38 cars, 2 buss, 11 trucks, 4 traffic lights, 30.7ms\n",
            "Speed: 1.1ms pre-process, 30.7ms inference, 2.3ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 2 buss, 12 trucks, 4 traffic lights, 30.6ms\n",
            "Speed: 1.1ms pre-process, 30.6ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 1 bus, 11 trucks, 4 traffic lights, 30.6ms\n",
            "Speed: 1.1ms pre-process, 30.6ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 1 bus, 13 trucks, 3 traffic lights, 30.7ms\n",
            "Speed: 1.0ms pre-process, 30.7ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 1 bus, 13 trucks, 3 traffic lights, 30.9ms\n",
            "Speed: 1.0ms pre-process, 30.9ms inference, 3.1ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 1 bus, 11 trucks, 3 traffic lights, 26.8ms\n",
            "Speed: 0.9ms pre-process, 26.8ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 48 cars, 1 bus, 11 trucks, 3 traffic lights, 26.9ms\n",
            "Speed: 1.3ms pre-process, 26.9ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 1 bus, 8 trucks, 4 traffic lights, 26.9ms\n",
            "Speed: 1.1ms pre-process, 26.9ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 2 buss, 10 trucks, 4 traffic lights, 26.0ms\n",
            "Speed: 1.1ms pre-process, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 2 buss, 13 trucks, 4 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 3 buss, 11 trucks, 4 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 1 bus, 10 trucks, 3 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 48 cars, 1 bus, 11 trucks, 3 traffic lights, 25.9ms\n",
            "Speed: 1.1ms pre-process, 25.9ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 1 bus, 8 trucks, 3 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 1 bus, 9 trucks, 3 traffic lights, 26.0ms\n",
            "Speed: 1.1ms pre-process, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 1 bus, 10 trucks, 3 traffic lights, 25.9ms\n",
            "Speed: 1.1ms pre-process, 25.9ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 1 bus, 10 trucks, 3 traffic lights, 26.0ms\n",
            "Speed: 1.1ms pre-process, 26.0ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 50 cars, 1 bus, 10 trucks, 4 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 52 cars, 1 bus, 10 trucks, 3 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 1 bus, 10 trucks, 4 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 1 bus, 12 trucks, 3 traffic lights, 26.1ms\n",
            "Speed: 1.0ms pre-process, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 1 bus, 10 trucks, 4 traffic lights, 26.0ms\n",
            "Speed: 0.9ms pre-process, 26.0ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 1 bus, 13 trucks, 4 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 49 cars, 1 bus, 12 trucks, 5 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 1 bus, 12 trucks, 4 traffic lights, 26.0ms\n",
            "Speed: 1.1ms pre-process, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 13 trucks, 3 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 1 bus, 11 trucks, 4 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 9 trucks, 4 traffic lights, 26.0ms\n",
            "Speed: 1.1ms pre-process, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 9 trucks, 4 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 8 trucks, 3 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 9 trucks, 4 traffic lights, 26.0ms\n",
            "Speed: 1.0ms pre-process, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 7 trucks, 4 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 7 trucks, 4 traffic lights, 26.0ms\n",
            "Speed: 1.1ms pre-process, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 5 trucks, 5 traffic lights, 25.9ms\n",
            "Speed: 1.1ms pre-process, 25.9ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 8 trucks, 7 traffic lights, 25.9ms\n",
            "Speed: 1.1ms pre-process, 25.9ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 8 trucks, 6 traffic lights, 25.9ms\n",
            "Speed: 1.1ms pre-process, 25.9ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 5 trucks, 6 traffic lights, 26.1ms\n",
            "Speed: 0.9ms pre-process, 26.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 6 trucks, 5 traffic lights, 26.2ms\n",
            "Speed: 1.0ms pre-process, 26.2ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 6 trucks, 5 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 6 trucks, 4 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 48 cars, 5 trucks, 4 traffic lights, 26.0ms\n",
            "Speed: 1.2ms pre-process, 26.0ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 37 cars, 6 trucks, 6 traffic lights, 25.1ms\n",
            "Speed: 1.0ms pre-process, 25.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 6 trucks, 6 traffic lights, 25.8ms\n",
            "Speed: 1.0ms pre-process, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 5 trucks, 5 traffic lights, 25.1ms\n",
            "Speed: 1.0ms pre-process, 25.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 1 bus, 6 trucks, 6 traffic lights, 25.1ms\n",
            "Speed: 1.0ms pre-process, 25.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 1 bus, 5 trucks, 6 traffic lights, 25.1ms\n",
            "Speed: 1.0ms pre-process, 25.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 49 cars, 1 bus, 5 trucks, 6 traffic lights, 25.2ms\n",
            "Speed: 1.1ms pre-process, 25.2ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 5 trucks, 5 traffic lights, 25.2ms\n",
            "Speed: 1.1ms pre-process, 25.2ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 7 trucks, 4 traffic lights, 25.1ms\n",
            "Speed: 1.0ms pre-process, 25.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 6 trucks, 4 traffic lights, 25.2ms\n",
            "Speed: 1.2ms pre-process, 25.2ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 6 trucks, 4 traffic lights, 25.2ms\n",
            "Speed: 1.6ms pre-process, 25.2ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 7 trucks, 5 traffic lights, 25.1ms\n",
            "Speed: 1.0ms pre-process, 25.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 9 trucks, 4 traffic lights, 25.1ms\n",
            "Speed: 1.0ms pre-process, 25.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 10 trucks, 4 traffic lights, 25.2ms\n",
            "Speed: 1.1ms pre-process, 25.2ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 8 trucks, 4 traffic lights, 25.1ms\n",
            "Speed: 1.0ms pre-process, 25.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 7 trucks, 5 traffic lights, 25.1ms\n",
            "Speed: 1.0ms pre-process, 25.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 8 trucks, 4 traffic lights, 25.1ms\n",
            "Speed: 1.0ms pre-process, 25.1ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 38 cars, 9 trucks, 5 traffic lights, 25.1ms\n",
            "Speed: 1.0ms pre-process, 25.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 8 trucks, 6 traffic lights, 25.1ms\n",
            "Speed: 1.0ms pre-process, 25.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 10 trucks, 5 traffic lights, 25.3ms\n",
            "Speed: 1.1ms pre-process, 25.3ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 9 trucks, 4 traffic lights, 25.3ms\n",
            "Speed: 0.9ms pre-process, 25.3ms inference, 3.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 8 trucks, 4 traffic lights, 25.2ms\n",
            "Speed: 1.0ms pre-process, 25.2ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 37 cars, 8 trucks, 5 traffic lights, 25.1ms\n",
            "Speed: 1.0ms pre-process, 25.1ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 45 cars, 10 trucks, 4 traffic lights, 25.1ms\n",
            "Speed: 0.9ms pre-process, 25.1ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 46 cars, 6 trucks, 5 traffic lights, 25.1ms\n",
            "Speed: 1.0ms pre-process, 25.1ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 42 cars, 9 trucks, 5 traffic lights, 25.2ms\n",
            "Speed: 1.1ms pre-process, 25.2ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 43 cars, 9 trucks, 5 traffic lights, 25.1ms\n",
            "Speed: 0.9ms pre-process, 25.1ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 7 trucks, 5 traffic lights, 25.2ms\n",
            "Speed: 1.1ms pre-process, 25.2ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 10 trucks, 5 traffic lights, 25.5ms\n",
            "Speed: 0.9ms pre-process, 25.5ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 39 cars, 7 trucks, 5 traffic lights, 25.7ms\n",
            "Speed: 1.0ms pre-process, 25.7ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 9 trucks, 5 traffic lights, 25.5ms\n",
            "Speed: 1.0ms pre-process, 25.5ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 8 trucks, 4 traffic lights, 25.5ms\n",
            "Speed: 1.0ms pre-process, 25.5ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 45 cars, 9 trucks, 4 traffic lights, 25.6ms\n",
            "Speed: 1.0ms pre-process, 25.6ms inference, 2.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 46 cars, 7 trucks, 5 traffic lights, 25.6ms\n",
            "Speed: 1.0ms pre-process, 25.6ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 39 cars, 1 bus, 11 trucks, 4 traffic lights, 25.7ms\n",
            "Speed: 2.4ms pre-process, 25.7ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 39 cars, 10 trucks, 4 traffic lights, 25.6ms\n",
            "Speed: 1.0ms pre-process, 25.6ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 38 cars, 7 trucks, 4 traffic lights, 26.2ms\n",
            "Speed: 1.0ms pre-process, 26.2ms inference, 2.3ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 44 cars, 10 trucks, 5 traffic lights, 25.5ms\n",
            "Speed: 0.9ms pre-process, 25.5ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 46 cars, 10 trucks, 5 traffic lights, 25.7ms\n",
            "Speed: 1.0ms pre-process, 25.7ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 43 cars, 9 trucks, 5 traffic lights, 25.6ms\n",
            "Speed: 1.1ms pre-process, 25.6ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 44 cars, 8 trucks, 6 traffic lights, 25.6ms\n",
            "Speed: 1.0ms pre-process, 25.6ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 43 cars, 1 bus, 9 trucks, 5 traffic lights, 25.7ms\n",
            "Speed: 1.0ms pre-process, 25.7ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 37 cars, 1 bus, 10 trucks, 5 traffic lights, 25.8ms\n",
            "Speed: 1.1ms pre-process, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 37 cars, 9 trucks, 5 traffic lights, 26.0ms\n",
            "Speed: 1.0ms pre-process, 26.0ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 40 cars, 1 bus, 5 trucks, 5 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 45 cars, 1 bus, 9 trucks, 5 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 39 cars, 1 bus, 4 trucks, 5 traffic lights, 25.9ms\n",
            "Speed: 1.1ms pre-process, 25.9ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 42 cars, 1 bus, 6 trucks, 4 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 40 cars, 1 bus, 6 trucks, 5 traffic lights, 25.7ms\n",
            "Speed: 1.1ms pre-process, 25.7ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 46 cars, 1 bus, 7 trucks, 5 traffic lights, 25.7ms\n",
            "Speed: 1.0ms pre-process, 25.7ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 49 cars, 1 bus, 8 trucks, 5 traffic lights, 25.8ms\n",
            "Speed: 1.0ms pre-process, 25.8ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 1 bus, 8 trucks, 4 traffic lights, 25.6ms\n",
            "Speed: 0.9ms pre-process, 25.6ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 1 bus, 6 trucks, 7 traffic lights, 25.6ms\n",
            "Speed: 1.1ms pre-process, 25.6ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 39 cars, 1 bus, 5 trucks, 5 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 2.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 1 bus, 6 trucks, 5 traffic lights, 25.6ms\n",
            "Speed: 1.1ms pre-process, 25.6ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 1 bus, 5 trucks, 5 traffic lights, 25.5ms\n",
            "Speed: 1.0ms pre-process, 25.5ms inference, 2.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 8 trucks, 5 traffic lights, 25.6ms\n",
            "Speed: 1.0ms pre-process, 25.6ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 8 trucks, 5 traffic lights, 25.6ms\n",
            "Speed: 0.9ms pre-process, 25.6ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 1 bus, 6 trucks, 7 traffic lights, 25.7ms\n",
            "Speed: 1.0ms pre-process, 25.7ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 1 bus, 6 trucks, 6 traffic lights, 25.4ms\n",
            "Speed: 0.9ms pre-process, 25.4ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 1 bus, 5 trucks, 6 traffic lights, 25.7ms\n",
            "Speed: 1.1ms pre-process, 25.7ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 1 bus, 7 trucks, 6 traffic lights, 25.6ms\n",
            "Speed: 1.1ms pre-process, 25.6ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 41 cars, 1 bus, 7 trucks, 5 traffic lights, 25.5ms\n",
            "Speed: 1.0ms pre-process, 25.5ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 1 bus, 5 trucks, 5 traffic lights, 1 suitcase, 25.5ms\n",
            "Speed: 1.1ms pre-process, 25.5ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 1 bus, 7 trucks, 5 traffic lights, 25.5ms\n",
            "Speed: 1.0ms pre-process, 25.5ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 1 bus, 6 trucks, 6 traffic lights, 25.6ms\n",
            "Speed: 0.9ms pre-process, 25.6ms inference, 2.1ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 1 bus, 8 trucks, 7 traffic lights, 25.8ms\n",
            "Speed: 1.0ms pre-process, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 36 cars, 1 bus, 10 trucks, 6 traffic lights, 25.5ms\n",
            "Speed: 1.0ms pre-process, 25.5ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 1 bus, 8 trucks, 5 traffic lights, 25.5ms\n",
            "Speed: 1.1ms pre-process, 25.5ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 8 trucks, 7 traffic lights, 25.7ms\n",
            "Speed: 1.0ms pre-process, 25.7ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 8 trucks, 6 traffic lights, 25.7ms\n",
            "Speed: 5.3ms pre-process, 25.7ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 8 trucks, 6 traffic lights, 25.7ms\n",
            "Speed: 1.1ms pre-process, 25.7ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 49 cars, 1 bus, 9 trucks, 5 traffic lights, 25.7ms\n",
            "Speed: 1.0ms pre-process, 25.7ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 49 cars, 1 bus, 6 trucks, 5 traffic lights, 25.5ms\n",
            "Speed: 0.9ms pre-process, 25.5ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 8 trucks, 7 traffic lights, 25.6ms\n",
            "Speed: 1.1ms pre-process, 25.6ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 7 trucks, 6 traffic lights, 24.9ms\n",
            "Speed: 0.9ms pre-process, 24.9ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 5 trucks, 6 traffic lights, 24.9ms\n",
            "Speed: 1.2ms pre-process, 24.9ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 7 trucks, 6 traffic lights, 24.7ms\n",
            "Speed: 0.9ms pre-process, 24.7ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 7 trucks, 5 traffic lights, 25.0ms\n",
            "Speed: 1.0ms pre-process, 25.0ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 6 trucks, 5 traffic lights, 24.8ms\n",
            "Speed: 1.1ms pre-process, 24.8ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 39 cars, 6 trucks, 4 traffic lights, 24.7ms\n",
            "Speed: 1.0ms pre-process, 24.7ms inference, 3.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 38 cars, 8 trucks, 5 traffic lights, 24.8ms\n",
            "Speed: 1.1ms pre-process, 24.8ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 7 trucks, 6 traffic lights, 1 suitcase, 25.3ms\n",
            "Speed: 1.1ms pre-process, 25.3ms inference, 2.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 43 cars, 8 trucks, 7 traffic lights, 24.8ms\n",
            "Speed: 1.0ms pre-process, 24.8ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 33 cars, 8 trucks, 7 traffic lights, 24.7ms\n",
            "Speed: 1.0ms pre-process, 24.7ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 37 cars, 7 trucks, 8 traffic lights, 26.5ms\n",
            "Speed: 1.0ms pre-process, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 6 trucks, 8 traffic lights, 24.7ms\n",
            "Speed: 1.0ms pre-process, 24.7ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 6 trucks, 7 traffic lights, 24.8ms\n",
            "Speed: 1.1ms pre-process, 24.8ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 9 trucks, 7 traffic lights, 24.8ms\n",
            "Speed: 1.1ms pre-process, 24.8ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 41 cars, 2 buss, 7 trucks, 7 traffic lights, 24.8ms\n",
            "Speed: 1.1ms pre-process, 24.8ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 38 cars, 7 trucks, 7 traffic lights, 24.8ms\n",
            "Speed: 1.1ms pre-process, 24.8ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 8 trucks, 7 traffic lights, 24.9ms\n",
            "Speed: 2.9ms pre-process, 24.9ms inference, 3.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 4 trucks, 7 traffic lights, 24.8ms\n",
            "Speed: 1.1ms pre-process, 24.8ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 5 trucks, 7 traffic lights, 24.7ms\n",
            "Speed: 1.0ms pre-process, 24.7ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 6 trucks, 7 traffic lights, 24.8ms\n",
            "Speed: 1.1ms pre-process, 24.8ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 3 trucks, 7 traffic lights, 24.8ms\n",
            "Speed: 1.0ms pre-process, 24.8ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 43 cars, 6 trucks, 7 traffic lights, 24.8ms\n",
            "Speed: 1.1ms pre-process, 24.8ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 5 trucks, 7 traffic lights, 25.2ms\n",
            "Speed: 1.1ms pre-process, 25.2ms inference, 2.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 41 cars, 3 trucks, 7 traffic lights, 24.8ms\n",
            "Speed: 1.0ms pre-process, 24.8ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 2 persons, 41 cars, 2 trucks, 7 traffic lights, 24.8ms\n",
            "Speed: 1.0ms pre-process, 24.8ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 5 trucks, 7 traffic lights, 24.8ms\n",
            "Speed: 1.0ms pre-process, 24.8ms inference, 2.3ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 43 cars, 5 trucks, 7 traffic lights, 24.8ms\n",
            "Speed: 1.1ms pre-process, 24.8ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 2 persons, 41 cars, 5 trucks, 7 traffic lights, 25.2ms\n",
            "Speed: 1.1ms pre-process, 25.2ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 39 cars, 7 trucks, 7 traffic lights, 25.2ms\n",
            "Speed: 1.1ms pre-process, 25.2ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 40 cars, 6 trucks, 7 traffic lights, 25.2ms\n",
            "Speed: 1.1ms pre-process, 25.2ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 2 persons, 42 cars, 5 trucks, 7 traffic lights, 25.7ms\n",
            "Speed: 1.0ms pre-process, 25.7ms inference, 3.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 2 persons, 42 cars, 4 trucks, 7 traffic lights, 25.5ms\n",
            "Speed: 1.0ms pre-process, 25.5ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 2 persons, 46 cars, 5 trucks, 6 traffic lights, 25.5ms\n",
            "Speed: 1.0ms pre-process, 25.5ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 48 cars, 5 trucks, 6 traffic lights, 25.7ms\n",
            "Speed: 1.0ms pre-process, 25.7ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 46 cars, 5 trucks, 5 traffic lights, 25.7ms\n",
            "Speed: 1.1ms pre-process, 25.7ms inference, 4.3ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 47 cars, 8 trucks, 5 traffic lights, 26.1ms\n",
            "Speed: 1.0ms pre-process, 26.1ms inference, 2.1ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 8 trucks, 5 traffic lights, 26.2ms\n",
            "Speed: 1.1ms pre-process, 26.2ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 8 trucks, 5 traffic lights, 28.5ms\n",
            "Speed: 1.0ms pre-process, 28.5ms inference, 3.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 5 trucks, 6 traffic lights, 25.9ms\n",
            "Speed: 1.2ms pre-process, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 39 cars, 8 trucks, 6 traffic lights, 27.3ms\n",
            "Speed: 1.0ms pre-process, 27.3ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 48 cars, 8 trucks, 6 traffic lights, 26.4ms\n",
            "Speed: 1.0ms pre-process, 26.4ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 6 trucks, 6 traffic lights, 26.5ms\n",
            "Speed: 1.0ms pre-process, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 7 trucks, 6 traffic lights, 26.4ms\n",
            "Speed: 4.7ms pre-process, 26.4ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 6 trucks, 6 traffic lights, 26.4ms\n",
            "Speed: 1.5ms pre-process, 26.4ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 7 trucks, 6 traffic lights, 26.4ms\n",
            "Speed: 1.0ms pre-process, 26.4ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 5 trucks, 5 traffic lights, 27.7ms\n",
            "Speed: 1.0ms pre-process, 27.7ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 48 cars, 4 trucks, 6 traffic lights, 27.3ms\n",
            "Speed: 1.1ms pre-process, 27.3ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 48 cars, 4 trucks, 5 traffic lights, 28.0ms\n",
            "Speed: 1.0ms pre-process, 28.0ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 5 trucks, 6 traffic lights, 27.9ms\n",
            "Speed: 1.0ms pre-process, 27.9ms inference, 2.1ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 6 trucks, 4 traffic lights, 28.1ms\n",
            "Speed: 1.0ms pre-process, 28.1ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 5 trucks, 5 traffic lights, 28.2ms\n",
            "Speed: 1.0ms pre-process, 28.2ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 4 trucks, 6 traffic lights, 30.1ms\n",
            "Speed: 1.0ms pre-process, 30.1ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 5 trucks, 5 traffic lights, 27.8ms\n",
            "Speed: 1.0ms pre-process, 27.8ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 6 trucks, 5 traffic lights, 27.7ms\n",
            "Speed: 1.0ms pre-process, 27.7ms inference, 2.3ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 5 trucks, 5 traffic lights, 27.8ms\n",
            "Speed: 1.0ms pre-process, 27.8ms inference, 2.3ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 5 trucks, 5 traffic lights, 33.4ms\n",
            "Speed: 1.0ms pre-process, 33.4ms inference, 2.1ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 6 trucks, 5 traffic lights, 30.3ms\n",
            "Speed: 1.0ms pre-process, 30.3ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 5 trucks, 6 traffic lights, 27.8ms\n",
            "Speed: 1.1ms pre-process, 27.8ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 1 bus, 4 trucks, 5 traffic lights, 27.9ms\n",
            "Speed: 1.1ms pre-process, 27.9ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 7 trucks, 5 traffic lights, 32.5ms\n",
            "Speed: 1.1ms pre-process, 32.5ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 48 cars, 6 trucks, 5 traffic lights, 27.7ms\n",
            "Speed: 1.0ms pre-process, 27.7ms inference, 2.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 5 trucks, 5 traffic lights, 27.7ms\n",
            "Speed: 1.1ms pre-process, 27.7ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 49 cars, 5 trucks, 5 traffic lights, 27.8ms\n",
            "Speed: 1.1ms pre-process, 27.8ms inference, 2.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 48 cars, 1 bus, 3 trucks, 6 traffic lights, 27.7ms\n",
            "Speed: 1.1ms pre-process, 27.7ms inference, 2.1ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 49 cars, 1 bus, 4 trucks, 5 traffic lights, 31.2ms\n",
            "Speed: 1.0ms pre-process, 31.2ms inference, 3.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 50 cars, 1 bus, 5 trucks, 5 traffic lights, 29.8ms\n",
            "Speed: 3.2ms pre-process, 29.8ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 49 cars, 1 bus, 5 trucks, 5 traffic lights, 27.7ms\n",
            "Speed: 1.1ms pre-process, 27.7ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 48 cars, 5 trucks, 4 traffic lights, 27.9ms\n",
            "Speed: 1.0ms pre-process, 27.9ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 4 trucks, 6 traffic lights, 27.8ms\n",
            "Speed: 1.1ms pre-process, 27.8ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 2 trucks, 6 traffic lights, 27.8ms\n",
            "Speed: 1.1ms pre-process, 27.8ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 48 cars, 3 trucks, 5 traffic lights, 27.8ms\n",
            "Speed: 1.1ms pre-process, 27.8ms inference, 3.3ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 48 cars, 2 trucks, 4 traffic lights, 27.8ms\n",
            "Speed: 1.0ms pre-process, 27.8ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 51 cars, 5 trucks, 4 traffic lights, 29.1ms\n",
            "Speed: 1.0ms pre-process, 29.1ms inference, 2.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 6 trucks, 4 traffic lights, 28.8ms\n",
            "Speed: 1.1ms pre-process, 28.8ms inference, 2.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 5 trucks, 4 traffic lights, 29.4ms\n",
            "Speed: 1.0ms pre-process, 29.4ms inference, 2.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 6 trucks, 5 traffic lights, 29.3ms\n",
            "Speed: 1.0ms pre-process, 29.3ms inference, 2.1ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 7 trucks, 5 traffic lights, 29.9ms\n",
            "Speed: 1.0ms pre-process, 29.9ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 5 trucks, 5 traffic lights, 29.9ms\n",
            "Speed: 1.0ms pre-process, 29.9ms inference, 2.1ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 3 trucks, 5 traffic lights, 29.9ms\n",
            "Speed: 5.1ms pre-process, 29.9ms inference, 2.1ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 3 trucks, 5 traffic lights, 32.3ms\n",
            "Speed: 1.1ms pre-process, 32.3ms inference, 2.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 4 trucks, 5 traffic lights, 30.1ms\n",
            "Speed: 1.1ms pre-process, 30.1ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 50 cars, 5 trucks, 5 traffic lights, 30.7ms\n",
            "Speed: 1.1ms pre-process, 30.7ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 48 cars, 4 trucks, 4 traffic lights, 30.5ms\n",
            "Speed: 1.1ms pre-process, 30.5ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 3 trucks, 4 traffic lights, 29.8ms\n",
            "Speed: 1.0ms pre-process, 29.8ms inference, 2.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 5 trucks, 5 traffic lights, 29.5ms\n",
            "Speed: 1.1ms pre-process, 29.5ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 4 trucks, 5 traffic lights, 29.5ms\n",
            "Speed: 1.0ms pre-process, 29.5ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 4 trucks, 5 traffic lights, 28.8ms\n",
            "Speed: 0.9ms pre-process, 28.8ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 43 cars, 4 trucks, 6 traffic lights, 28.9ms\n",
            "Speed: 1.0ms pre-process, 28.9ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 3 trucks, 6 traffic lights, 28.8ms\n",
            "Speed: 1.1ms pre-process, 28.8ms inference, 2.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 4 trucks, 6 traffic lights, 26.4ms\n",
            "Speed: 1.1ms pre-process, 26.4ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 3 trucks, 6 traffic lights, 26.3ms\n",
            "Speed: 1.0ms pre-process, 26.3ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 5 trucks, 6 traffic lights, 26.4ms\n",
            "Speed: 1.1ms pre-process, 26.4ms inference, 3.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 4 trucks, 5 traffic lights, 26.0ms\n",
            "Speed: 1.1ms pre-process, 26.0ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 48 cars, 4 trucks, 5 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 49 cars, 5 trucks, 6 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 48 cars, 7 trucks, 5 traffic lights, 24.7ms\n",
            "Speed: 1.0ms pre-process, 24.7ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 9 trucks, 6 traffic lights, 24.2ms\n",
            "Speed: 1.0ms pre-process, 24.2ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 8 trucks, 5 traffic lights, 24.1ms\n",
            "Speed: 1.0ms pre-process, 24.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 5 trucks, 4 traffic lights, 24.0ms\n",
            "Speed: 1.0ms pre-process, 24.0ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 7 trucks, 4 traffic lights, 24.0ms\n",
            "Speed: 1.0ms pre-process, 24.0ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 37 cars, 6 trucks, 5 traffic lights, 24.1ms\n",
            "Speed: 1.0ms pre-process, 24.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 36 cars, 7 trucks, 4 traffic lights, 24.1ms\n",
            "Speed: 1.1ms pre-process, 24.1ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 1 bus, 4 trucks, 5 traffic lights, 24.1ms\n",
            "Speed: 1.0ms pre-process, 24.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 38 cars, 1 bus, 5 trucks, 5 traffic lights, 24.1ms\n",
            "Speed: 1.1ms pre-process, 24.1ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 38 cars, 2 buss, 5 trucks, 5 traffic lights, 24.1ms\n",
            "Speed: 1.1ms pre-process, 24.1ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 6 trucks, 5 traffic lights, 24.1ms\n",
            "Speed: 1.0ms pre-process, 24.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 6 trucks, 5 traffic lights, 24.1ms\n",
            "Speed: 1.1ms pre-process, 24.1ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 36 cars, 6 trucks, 6 traffic lights, 23.8ms\n",
            "Speed: 0.9ms pre-process, 23.8ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 37 cars, 7 trucks, 5 traffic lights, 23.5ms\n",
            "Speed: 1.1ms pre-process, 23.5ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 37 cars, 6 trucks, 5 traffic lights, 23.4ms\n",
            "Speed: 0.9ms pre-process, 23.4ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 36 cars, 7 trucks, 7 traffic lights, 23.5ms\n",
            "Speed: 1.1ms pre-process, 23.5ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 35 cars, 6 trucks, 6 traffic lights, 23.2ms\n",
            "Speed: 1.0ms pre-process, 23.2ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 36 cars, 7 trucks, 6 traffic lights, 23.2ms\n",
            "Speed: 1.0ms pre-process, 23.2ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 34 cars, 1 bus, 6 trucks, 6 traffic lights, 23.2ms\n",
            "Speed: 1.1ms pre-process, 23.2ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 36 cars, 7 trucks, 4 traffic lights, 23.2ms\n",
            "Speed: 1.0ms pre-process, 23.2ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 6 trucks, 6 traffic lights, 23.1ms\n",
            "Speed: 1.1ms pre-process, 23.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 39 cars, 7 trucks, 4 traffic lights, 23.2ms\n",
            "Speed: 1.2ms pre-process, 23.2ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 1 bus, 9 trucks, 5 traffic lights, 23.1ms\n",
            "Speed: 1.0ms pre-process, 23.1ms inference, 2.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 35 cars, 2 buss, 6 trucks, 5 traffic lights, 23.2ms\n",
            "Speed: 1.1ms pre-process, 23.2ms inference, 3.3ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 39 cars, 1 bus, 8 trucks, 4 traffic lights, 24.9ms\n",
            "Speed: 1.1ms pre-process, 24.9ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 1 bus, 8 trucks, 4 traffic lights, 23.1ms\n",
            "Speed: 1.0ms pre-process, 23.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 39 cars, 1 bus, 9 trucks, 4 traffic lights, 23.1ms\n",
            "Speed: 1.0ms pre-process, 23.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 2 buss, 7 trucks, 4 traffic lights, 23.3ms\n",
            "Speed: 1.2ms pre-process, 23.3ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 48 cars, 1 bus, 6 trucks, 4 traffic lights, 23.2ms\n",
            "Speed: 1.1ms pre-process, 23.2ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 1 bus, 6 trucks, 5 traffic lights, 23.2ms\n",
            "Speed: 1.1ms pre-process, 23.2ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 1 bus, 5 trucks, 4 traffic lights, 23.2ms\n",
            "Speed: 1.0ms pre-process, 23.2ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 2 buss, 4 trucks, 5 traffic lights, 23.2ms\n",
            "Speed: 1.1ms pre-process, 23.2ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 2 buss, 3 trucks, 5 traffic lights, 23.1ms\n",
            "Speed: 1.1ms pre-process, 23.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 2 buss, 4 trucks, 7 traffic lights, 23.1ms\n",
            "Speed: 1.0ms pre-process, 23.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 2 buss, 3 trucks, 7 traffic lights, 23.1ms\n",
            "Speed: 1.1ms pre-process, 23.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 2 buss, 3 trucks, 6 traffic lights, 23.2ms\n",
            "Speed: 1.0ms pre-process, 23.2ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 2 buss, 3 trucks, 6 traffic lights, 23.2ms\n",
            "Speed: 1.0ms pre-process, 23.2ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 3 buss, 3 trucks, 4 traffic lights, 23.2ms\n",
            "Speed: 1.0ms pre-process, 23.2ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 38 cars, 3 buss, 3 trucks, 4 traffic lights, 23.3ms\n",
            "Speed: 1.1ms pre-process, 23.3ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 39 cars, 2 buss, 4 trucks, 4 traffic lights, 23.1ms\n",
            "Speed: 1.0ms pre-process, 23.1ms inference, 2.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 1 bus, 5 trucks, 5 traffic lights, 23.2ms\n",
            "Speed: 0.9ms pre-process, 23.2ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 2 buss, 6 trucks, 4 traffic lights, 23.1ms\n",
            "Speed: 1.0ms pre-process, 23.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 1 bus, 5 trucks, 5 traffic lights, 23.1ms\n",
            "Speed: 1.0ms pre-process, 23.1ms inference, 3.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 38 cars, 2 buss, 5 trucks, 7 traffic lights, 24.4ms\n",
            "Speed: 1.0ms pre-process, 24.4ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 37 cars, 1 bus, 5 trucks, 8 traffic lights, 24.4ms\n",
            "Speed: 1.0ms pre-process, 24.4ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 38 cars, 2 buss, 5 trucks, 4 traffic lights, 24.4ms\n",
            "Speed: 1.0ms pre-process, 24.4ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 1 bus, 6 trucks, 7 traffic lights, 24.7ms\n",
            "Speed: 0.9ms pre-process, 24.7ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 39 cars, 3 buss, 4 trucks, 4 traffic lights, 24.8ms\n",
            "Speed: 1.1ms pre-process, 24.8ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 39 cars, 1 bus, 7 trucks, 4 traffic lights, 24.7ms\n",
            "Speed: 1.0ms pre-process, 24.7ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 37 cars, 2 buss, 6 trucks, 5 traffic lights, 24.8ms\n",
            "Speed: 1.0ms pre-process, 24.8ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 31 cars, 2 buss, 6 trucks, 7 traffic lights, 24.8ms\n",
            "Speed: 0.9ms pre-process, 24.8ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 31 cars, 2 buss, 5 trucks, 7 traffic lights, 24.7ms\n",
            "Speed: 1.0ms pre-process, 24.7ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 34 cars, 3 buss, 5 trucks, 8 traffic lights, 24.1ms\n",
            "Speed: 1.0ms pre-process, 24.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 38 cars, 1 bus, 4 trucks, 7 traffic lights, 23.7ms\n",
            "Speed: 1.0ms pre-process, 23.7ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 38 cars, 1 bus, 4 trucks, 6 traffic lights, 23.7ms\n",
            "Speed: 1.0ms pre-process, 23.7ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 36 cars, 1 bus, 3 trucks, 7 traffic lights, 23.9ms\n",
            "Speed: 1.0ms pre-process, 23.9ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 38 cars, 1 bus, 3 trucks, 7 traffic lights, 23.8ms\n",
            "Speed: 1.1ms pre-process, 23.8ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 3 buss, 4 trucks, 8 traffic lights, 23.7ms\n",
            "Speed: 1.0ms pre-process, 23.7ms inference, 2.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 34 cars, 2 buss, 3 trucks, 5 traffic lights, 23.7ms\n",
            "Speed: 1.1ms pre-process, 23.7ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 34 cars, 3 buss, 2 trucks, 6 traffic lights, 23.8ms\n",
            "Speed: 1.0ms pre-process, 23.8ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 1 bus, 3 trucks, 8 traffic lights, 23.8ms\n",
            "Speed: 1.1ms pre-process, 23.8ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 39 cars, 1 bus, 2 trucks, 8 traffic lights, 23.8ms\n",
            "Speed: 1.1ms pre-process, 23.8ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 33 cars, 1 bus, 1 truck, 5 traffic lights, 23.8ms\n",
            "Speed: 1.0ms pre-process, 23.8ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 37 cars, 2 buss, 3 trucks, 4 traffic lights, 23.8ms\n",
            "Speed: 1.0ms pre-process, 23.8ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 38 cars, 3 buss, 1 truck, 5 traffic lights, 23.8ms\n",
            "Speed: 1.0ms pre-process, 23.8ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 2 buss, 2 trucks, 4 traffic lights, 1 suitcase, 23.9ms\n",
            "Speed: 1.0ms pre-process, 23.9ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 35 cars, 2 buss, 6 traffic lights, 23.7ms\n",
            "Speed: 0.9ms pre-process, 23.7ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 34 cars, 1 bus, 1 truck, 6 traffic lights, 23.8ms\n",
            "Speed: 1.1ms pre-process, 23.8ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 36 cars, 2 buss, 1 truck, 5 traffic lights, 22.7ms\n",
            "Speed: 1.0ms pre-process, 22.7ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 35 cars, 2 buss, 6 traffic lights, 22.6ms\n",
            "Speed: 1.0ms pre-process, 22.6ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 37 cars, 2 buss, 7 traffic lights, 22.7ms\n",
            "Speed: 1.0ms pre-process, 22.7ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 2 buss, 2 trucks, 4 traffic lights, 22.6ms\n",
            "Speed: 0.9ms pre-process, 22.6ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 37 cars, 2 buss, 1 truck, 4 traffic lights, 22.6ms\n",
            "Speed: 0.9ms pre-process, 22.6ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 2 buss, 2 trucks, 5 traffic lights, 22.7ms\n",
            "Speed: 1.0ms pre-process, 22.7ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 1 bus, 1 truck, 5 traffic lights, 22.6ms\n",
            "Speed: 1.1ms pre-process, 22.6ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 2 buss, 4 trucks, 5 traffic lights, 22.6ms\n",
            "Speed: 1.0ms pre-process, 22.6ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 38 cars, 1 bus, 3 trucks, 6 traffic lights, 22.6ms\n",
            "Speed: 1.1ms pre-process, 22.6ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 1 bus, 4 trucks, 7 traffic lights, 22.6ms\n",
            "Speed: 1.0ms pre-process, 22.6ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 1 bus, 3 trucks, 7 traffic lights, 22.7ms\n",
            "Speed: 1.0ms pre-process, 22.7ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 2 buss, 3 trucks, 8 traffic lights, 22.7ms\n",
            "Speed: 1.1ms pre-process, 22.7ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 1 bus, 3 trucks, 8 traffic lights, 22.7ms\n",
            "Speed: 1.1ms pre-process, 22.7ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 1 bus, 3 trucks, 6 traffic lights, 22.8ms\n",
            "Speed: 1.1ms pre-process, 22.8ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 1 bus, 2 trucks, 5 traffic lights, 22.8ms\n",
            "Speed: 1.1ms pre-process, 22.8ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 1 bus, 2 trucks, 5 traffic lights, 22.6ms\n",
            "Speed: 1.0ms pre-process, 22.6ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 1 bus, 4 trucks, 5 traffic lights, 22.6ms\n",
            "Speed: 1.0ms pre-process, 22.6ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 2 buss, 2 trucks, 7 traffic lights, 22.6ms\n",
            "Speed: 1.1ms pre-process, 22.6ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 1 bus, 4 trucks, 4 traffic lights, 22.7ms\n",
            "Speed: 2.1ms pre-process, 22.7ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 1 bus, 3 trucks, 6 traffic lights, 22.6ms\n",
            "Speed: 1.0ms pre-process, 22.6ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 4 trucks, 6 traffic lights, 22.6ms\n",
            "Speed: 1.1ms pre-process, 22.6ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 1 bus, 3 trucks, 5 traffic lights, 22.6ms\n",
            "Speed: 1.1ms pre-process, 22.6ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 1 bus, 3 trucks, 5 traffic lights, 22.6ms\n",
            "Speed: 1.0ms pre-process, 22.6ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 4 trucks, 7 traffic lights, 22.6ms\n",
            "Speed: 1.1ms pre-process, 22.6ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 2 buss, 4 trucks, 7 traffic lights, 22.6ms\n",
            "Speed: 1.1ms pre-process, 22.6ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 39 cars, 3 trucks, 7 traffic lights, 22.8ms\n",
            "Speed: 1.0ms pre-process, 22.8ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 43 cars, 1 bus, 3 trucks, 8 traffic lights, 22.6ms\n",
            "Speed: 1.0ms pre-process, 22.6ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 4 trucks, 8 traffic lights, 22.7ms\n",
            "Speed: 1.0ms pre-process, 22.7ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 1 bus, 2 trucks, 9 traffic lights, 22.9ms\n",
            "Speed: 1.2ms pre-process, 22.9ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 1 bus, 4 trucks, 6 traffic lights, 22.9ms\n",
            "Speed: 1.0ms pre-process, 22.9ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 2 trucks, 7 traffic lights, 22.9ms\n",
            "Speed: 1.0ms pre-process, 22.9ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 36 cars, 3 trucks, 6 traffic lights, 22.8ms\n",
            "Speed: 1.0ms pre-process, 22.8ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 3 trucks, 9 traffic lights, 23.0ms\n",
            "Speed: 1.1ms pre-process, 23.0ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 4 trucks, 8 traffic lights, 22.9ms\n",
            "Speed: 1.0ms pre-process, 22.9ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 1 bus, 3 trucks, 9 traffic lights, 23.3ms\n",
            "Speed: 1.0ms pre-process, 23.3ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 1 bus, 5 trucks, 8 traffic lights, 23.1ms\n",
            "Speed: 6.4ms pre-process, 23.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 1 bus, 4 trucks, 9 traffic lights, 23.1ms\n",
            "Speed: 1.0ms pre-process, 23.1ms inference, 2.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 5 trucks, 7 traffic lights, 23.1ms\n",
            "Speed: 0.9ms pre-process, 23.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 5 trucks, 8 traffic lights, 23.2ms\n",
            "Speed: 1.0ms pre-process, 23.2ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 36 cars, 1 bus, 5 trucks, 6 traffic lights, 23.4ms\n",
            "Speed: 1.1ms pre-process, 23.4ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 37 cars, 1 bus, 7 trucks, 8 traffic lights, 23.8ms\n",
            "Speed: 0.9ms pre-process, 23.8ms inference, 2.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 37 cars, 1 bus, 5 trucks, 7 traffic lights, 23.5ms\n",
            "Speed: 1.1ms pre-process, 23.5ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 38 cars, 3 trucks, 6 traffic lights, 23.5ms\n",
            "Speed: 1.0ms pre-process, 23.5ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 38 cars, 6 trucks, 5 traffic lights, 23.4ms\n",
            "Speed: 0.9ms pre-process, 23.4ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 38 cars, 5 trucks, 3 traffic lights, 23.5ms\n",
            "Speed: 1.1ms pre-process, 23.5ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 3 trucks, 4 traffic lights, 23.5ms\n",
            "Speed: 1.0ms pre-process, 23.5ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 3 trucks, 5 traffic lights, 23.9ms\n",
            "Speed: 1.2ms pre-process, 23.9ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 48 cars, 4 trucks, 4 traffic lights, 23.8ms\n",
            "Speed: 1.0ms pre-process, 23.8ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 49 cars, 3 trucks, 4 traffic lights, 23.8ms\n",
            "Speed: 1.1ms pre-process, 23.8ms inference, 3.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 4 trucks, 3 traffic lights, 23.8ms\n",
            "Speed: 0.9ms pre-process, 23.8ms inference, 2.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 2 trucks, 5 traffic lights, 23.8ms\n",
            "Speed: 1.0ms pre-process, 23.8ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 46 cars, 1 truck, 7 traffic lights, 23.7ms\n",
            "Speed: 1.0ms pre-process, 23.7ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 50 cars, 1 truck, 6 traffic lights, 23.7ms\n",
            "Speed: 1.0ms pre-process, 23.7ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 55 cars, 2 trucks, 5 traffic lights, 23.7ms\n",
            "Speed: 1.0ms pre-process, 23.7ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 49 cars, 1 truck, 6 traffic lights, 24.1ms\n",
            "Speed: 1.0ms pre-process, 24.1ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 39 cars, 1 truck, 4 traffic lights, 24.2ms\n",
            "Speed: 1.0ms pre-process, 24.2ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 4 trucks, 5 traffic lights, 24.0ms\n",
            "Speed: 1.0ms pre-process, 24.0ms inference, 3.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 2 trucks, 6 traffic lights, 24.5ms\n",
            "Speed: 1.0ms pre-process, 24.5ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 3 trucks, 7 traffic lights, 24.0ms\n",
            "Speed: 1.0ms pre-process, 24.0ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 3 trucks, 7 traffic lights, 24.2ms\n",
            "Speed: 1.1ms pre-process, 24.2ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 4 trucks, 5 traffic lights, 24.1ms\n",
            "Speed: 1.0ms pre-process, 24.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 47 cars, 3 trucks, 4 traffic lights, 24.1ms\n",
            "Speed: 1.1ms pre-process, 24.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 46 cars, 4 trucks, 6 traffic lights, 24.1ms\n",
            "Speed: 1.1ms pre-process, 24.1ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 3 trucks, 6 traffic lights, 24.1ms\n",
            "Speed: 1.0ms pre-process, 24.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 39 cars, 4 trucks, 5 traffic lights, 24.4ms\n",
            "Speed: 0.9ms pre-process, 24.4ms inference, 2.1ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 37 cars, 3 trucks, 6 traffic lights, 24.5ms\n",
            "Speed: 1.1ms pre-process, 24.5ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 4 trucks, 6 traffic lights, 24.4ms\n",
            "Speed: 1.0ms pre-process, 24.4ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 2 trucks, 6 traffic lights, 24.4ms\n",
            "Speed: 1.0ms pre-process, 24.4ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 2 trucks, 5 traffic lights, 24.4ms\n",
            "Speed: 1.0ms pre-process, 24.4ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 48 cars, 3 trucks, 6 traffic lights, 24.5ms\n",
            "Speed: 1.2ms pre-process, 24.5ms inference, 2.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 3 trucks, 4 traffic lights, 24.5ms\n",
            "Speed: 1.1ms pre-process, 24.5ms inference, 2.3ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 43 cars, 1 bus, 6 trucks, 4 traffic lights, 24.6ms\n",
            "Speed: 1.2ms pre-process, 24.6ms inference, 2.1ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 43 cars, 5 trucks, 4 traffic lights, 25.2ms\n",
            "Speed: 1.0ms pre-process, 25.2ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 42 cars, 5 trucks, 5 traffic lights, 25.2ms\n",
            "Speed: 1.0ms pre-process, 25.2ms inference, 2.1ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 43 cars, 4 trucks, 7 traffic lights, 25.2ms\n",
            "Speed: 1.0ms pre-process, 25.2ms inference, 2.3ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 37 cars, 3 trucks, 5 traffic lights, 25.1ms\n",
            "Speed: 1.1ms pre-process, 25.1ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 3 trucks, 5 traffic lights, 25.1ms\n",
            "Speed: 1.0ms pre-process, 25.1ms inference, 2.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 37 cars, 3 trucks, 4 traffic lights, 25.6ms\n",
            "Speed: 2.8ms pre-process, 25.6ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 4 trucks, 4 traffic lights, 25.6ms\n",
            "Speed: 1.0ms pre-process, 25.6ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 38 cars, 3 trucks, 4 traffic lights, 26.4ms\n",
            "Speed: 1.1ms pre-process, 26.4ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 3 trucks, 5 traffic lights, 26.5ms\n",
            "Speed: 1.1ms pre-process, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 3 trucks, 5 traffic lights, 26.8ms\n",
            "Speed: 1.1ms pre-process, 26.8ms inference, 2.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 3 trucks, 5 traffic lights, 26.7ms\n",
            "Speed: 1.1ms pre-process, 26.7ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 49 cars, 4 trucks, 6 traffic lights, 26.4ms\n",
            "Speed: 1.0ms pre-process, 26.4ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 49 cars, 4 trucks, 5 traffic lights, 26.9ms\n",
            "Speed: 1.0ms pre-process, 26.9ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 49 cars, 3 trucks, 7 traffic lights, 26.8ms\n",
            "Speed: 1.0ms pre-process, 26.8ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 2 trucks, 7 traffic lights, 27.2ms\n",
            "Speed: 1.1ms pre-process, 27.2ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 4 trucks, 6 traffic lights, 27.3ms\n",
            "Speed: 1.2ms pre-process, 27.3ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 3 trucks, 5 traffic lights, 27.8ms\n",
            "Speed: 1.0ms pre-process, 27.8ms inference, 4.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 51 cars, 4 trucks, 6 traffic lights, 27.7ms\n",
            "Speed: 1.1ms pre-process, 27.7ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 50 cars, 4 trucks, 6 traffic lights, 28.8ms\n",
            "Speed: 1.1ms pre-process, 28.8ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 47 cars, 6 trucks, 6 traffic lights, 28.7ms\n",
            "Speed: 1.0ms pre-process, 28.7ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 42 cars, 4 trucks, 7 traffic lights, 30.6ms\n",
            "Speed: 1.0ms pre-process, 30.6ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 43 cars, 6 trucks, 6 traffic lights, 28.8ms\n",
            "Speed: 1.0ms pre-process, 28.8ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 38 cars, 5 trucks, 6 traffic lights, 28.8ms\n",
            "Speed: 1.0ms pre-process, 28.8ms inference, 2.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 39 cars, 5 trucks, 6 traffic lights, 29.0ms\n",
            "Speed: 1.1ms pre-process, 29.0ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 42 cars, 3 trucks, 6 traffic lights, 28.7ms\n",
            "Speed: 1.0ms pre-process, 28.7ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 2 persons, 39 cars, 5 trucks, 5 traffic lights, 30.0ms\n",
            "Speed: 1.2ms pre-process, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 4 trucks, 6 traffic lights, 29.5ms\n",
            "Speed: 1.1ms pre-process, 29.5ms inference, 2.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 45 cars, 3 trucks, 7 traffic lights, 31.8ms\n",
            "Speed: 1.1ms pre-process, 31.8ms inference, 2.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 48 cars, 4 trucks, 6 traffic lights, 29.9ms\n",
            "Speed: 1.0ms pre-process, 29.9ms inference, 3.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 4 trucks, 6 traffic lights, 36.8ms\n",
            "Speed: 1.0ms pre-process, 36.8ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 4 trucks, 6 traffic lights, 30.0ms\n",
            "Speed: 1.1ms pre-process, 30.0ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 6 trucks, 6 traffic lights, 29.9ms\n",
            "Speed: 1.1ms pre-process, 29.9ms inference, 3.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 41 cars, 5 trucks, 5 traffic lights, 33.0ms\n",
            "Speed: 1.1ms pre-process, 33.0ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 5 trucks, 6 traffic lights, 30.6ms\n",
            "Speed: 1.0ms pre-process, 30.6ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 5 trucks, 6 traffic lights, 30.6ms\n",
            "Speed: 1.0ms pre-process, 30.6ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 6 trucks, 6 traffic lights, 30.5ms\n",
            "Speed: 1.0ms pre-process, 30.5ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 5 trucks, 7 traffic lights, 30.5ms\n",
            "Speed: 1.2ms pre-process, 30.5ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 8 trucks, 6 traffic lights, 30.6ms\n",
            "Speed: 1.1ms pre-process, 30.6ms inference, 2.1ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 4 trucks, 6 traffic lights, 35.2ms\n",
            "Speed: 1.1ms pre-process, 35.2ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 5 trucks, 6 traffic lights, 30.7ms\n",
            "Speed: 1.1ms pre-process, 30.7ms inference, 2.1ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 1 bus, 5 trucks, 6 traffic lights, 30.7ms\n",
            "Speed: 1.1ms pre-process, 30.7ms inference, 2.3ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 7 trucks, 6 traffic lights, 30.6ms\n",
            "Speed: 1.0ms pre-process, 30.6ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 49 cars, 6 trucks, 7 traffic lights, 31.7ms\n",
            "Speed: 1.0ms pre-process, 31.7ms inference, 2.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 5 trucks, 6 traffic lights, 30.5ms\n",
            "Speed: 1.2ms pre-process, 30.5ms inference, 2.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 6 trucks, 6 traffic lights, 33.9ms\n",
            "Speed: 1.1ms pre-process, 33.9ms inference, 2.1ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 46 cars, 4 trucks, 6 traffic lights, 30.5ms\n",
            "Speed: 1.0ms pre-process, 30.5ms inference, 2.1ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 5 trucks, 6 traffic lights, 30.5ms\n",
            "Speed: 1.0ms pre-process, 30.5ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 4 trucks, 7 traffic lights, 30.5ms\n",
            "Speed: 1.0ms pre-process, 30.5ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 52 cars, 5 trucks, 7 traffic lights, 30.8ms\n",
            "Speed: 1.1ms pre-process, 30.8ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 54 cars, 5 trucks, 8 traffic lights, 30.6ms\n",
            "Speed: 1.0ms pre-process, 30.6ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 53 cars, 5 trucks, 7 traffic lights, 35.0ms\n",
            "Speed: 1.1ms pre-process, 35.0ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 54 cars, 6 trucks, 7 traffic lights, 27.0ms\n",
            "Speed: 1.0ms pre-process, 27.0ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 50 cars, 4 trucks, 8 traffic lights, 26.9ms\n",
            "Speed: 0.9ms pre-process, 26.9ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 5 trucks, 6 traffic lights, 26.5ms\n",
            "Speed: 1.0ms pre-process, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 51 cars, 4 trucks, 6 traffic lights, 26.8ms\n",
            "Speed: 1.1ms pre-process, 26.8ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 52 cars, 1 bus, 4 trucks, 5 traffic lights, 26.8ms\n",
            "Speed: 1.0ms pre-process, 26.8ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 1 bus, 6 trucks, 6 traffic lights, 27.1ms\n",
            "Speed: 1.1ms pre-process, 27.1ms inference, 2.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 1 bus, 4 trucks, 6 traffic lights, 26.5ms\n",
            "Speed: 1.0ms pre-process, 26.5ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 2 buss, 5 trucks, 8 traffic lights, 26.7ms\n",
            "Speed: 1.0ms pre-process, 26.7ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 1 bus, 4 trucks, 7 traffic lights, 1 suitcase, 26.4ms\n",
            "Speed: 1.1ms pre-process, 26.4ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 1 bus, 5 trucks, 7 traffic lights, 26.3ms\n",
            "Speed: 1.0ms pre-process, 26.3ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 1 bus, 6 trucks, 6 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 1 bus, 6 trucks, 7 traffic lights, 25.5ms\n",
            "Speed: 1.0ms pre-process, 25.5ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 45 cars, 1 bus, 7 trucks, 7 traffic lights, 25.5ms\n",
            "Speed: 2.8ms pre-process, 25.5ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 1 bus, 8 trucks, 7 traffic lights, 25.2ms\n",
            "Speed: 1.1ms pre-process, 25.2ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 1 bus, 7 trucks, 7 traffic lights, 24.1ms\n",
            "Speed: 1.1ms pre-process, 24.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 1 bus, 7 trucks, 7 traffic lights, 24.1ms\n",
            "Speed: 1.1ms pre-process, 24.1ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 37 cars, 1 bus, 8 trucks, 7 traffic lights, 24.1ms\n",
            "Speed: 0.9ms pre-process, 24.1ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 1 bus, 7 trucks, 7 traffic lights, 24.2ms\n",
            "Speed: 1.0ms pre-process, 24.2ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 3 buss, 8 trucks, 8 traffic lights, 24.0ms\n",
            "Speed: 1.0ms pre-process, 24.0ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 1 bus, 7 trucks, 8 traffic lights, 24.0ms\n",
            "Speed: 1.0ms pre-process, 24.0ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 1 bus, 7 trucks, 7 traffic lights, 24.1ms\n",
            "Speed: 1.0ms pre-process, 24.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 1 bus, 7 trucks, 6 traffic lights, 24.1ms\n",
            "Speed: 1.0ms pre-process, 24.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 2 buss, 8 trucks, 7 traffic lights, 24.0ms\n",
            "Speed: 1.0ms pre-process, 24.0ms inference, 2.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 1 bus, 8 trucks, 7 traffic lights, 23.7ms\n",
            "Speed: 0.9ms pre-process, 23.7ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 49 cars, 1 bus, 7 trucks, 8 traffic lights, 23.8ms\n",
            "Speed: 1.1ms pre-process, 23.8ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 51 cars, 1 bus, 7 trucks, 7 traffic lights, 23.7ms\n",
            "Speed: 1.0ms pre-process, 23.7ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 52 cars, 1 bus, 6 trucks, 7 traffic lights, 23.7ms\n",
            "Speed: 1.0ms pre-process, 23.7ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 50 cars, 1 bus, 6 trucks, 8 traffic lights, 23.7ms\n",
            "Speed: 1.0ms pre-process, 23.7ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 48 cars, 1 bus, 5 trucks, 8 traffic lights, 23.7ms\n",
            "Speed: 1.0ms pre-process, 23.7ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 1 bus, 6 trucks, 7 traffic lights, 23.8ms\n",
            "Speed: 1.0ms pre-process, 23.8ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 1 bus, 6 trucks, 7 traffic lights, 23.7ms\n",
            "Speed: 2.1ms pre-process, 23.7ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 50 cars, 1 bus, 6 trucks, 7 traffic lights, 23.8ms\n",
            "Speed: 1.1ms pre-process, 23.8ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 51 cars, 1 bus, 5 trucks, 8 traffic lights, 24.3ms\n",
            "Speed: 1.0ms pre-process, 24.3ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 1 bus, 8 trucks, 8 traffic lights, 23.8ms\n",
            "Speed: 2.0ms pre-process, 23.8ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 1 bus, 6 trucks, 7 traffic lights, 23.8ms\n",
            "Speed: 1.1ms pre-process, 23.8ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 5 trucks, 7 traffic lights, 23.8ms\n",
            "Speed: 1.0ms pre-process, 23.8ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 1 bus, 8 trucks, 6 traffic lights, 23.7ms\n",
            "Speed: 1.0ms pre-process, 23.7ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 1 bus, 6 trucks, 7 traffic lights, 24.0ms\n",
            "Speed: 1.1ms pre-process, 24.0ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 1 bus, 6 trucks, 6 traffic lights, 23.8ms\n",
            "Speed: 1.1ms pre-process, 23.8ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 1 bus, 6 trucks, 6 traffic lights, 23.8ms\n",
            "Speed: 1.0ms pre-process, 23.8ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 1 bus, 7 trucks, 6 traffic lights, 23.7ms\n",
            "Speed: 0.9ms pre-process, 23.7ms inference, 2.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 1 bus, 6 trucks, 6 traffic lights, 23.8ms\n",
            "Speed: 1.0ms pre-process, 23.8ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 1 bus, 4 trucks, 7 traffic lights, 23.8ms\n",
            "Speed: 1.0ms pre-process, 23.8ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 1 bus, 4 trucks, 7 traffic lights, 23.7ms\n",
            "Speed: 1.0ms pre-process, 23.7ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 46 cars, 1 bus, 5 trucks, 7 traffic lights, 23.8ms\n",
            "Speed: 1.0ms pre-process, 23.8ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 52 cars, 2 buss, 4 trucks, 6 traffic lights, 23.9ms\n",
            "Speed: 1.1ms pre-process, 23.9ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 3 trucks, 8 traffic lights, 23.7ms\n",
            "Speed: 1.1ms pre-process, 23.7ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 48 cars, 1 bus, 4 trucks, 7 traffic lights, 23.8ms\n",
            "Speed: 1.0ms pre-process, 23.8ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 1 bus, 3 trucks, 5 traffic lights, 29.8ms\n",
            "Speed: 1.0ms pre-process, 29.8ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 2 buss, 4 trucks, 7 traffic lights, 24.0ms\n",
            "Speed: 1.0ms pre-process, 24.0ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 2 buss, 5 trucks, 6 traffic lights, 25.3ms\n",
            "Speed: 1.4ms pre-process, 25.3ms inference, 2.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 2 buss, 5 trucks, 9 traffic lights, 24.4ms\n",
            "Speed: 1.0ms pre-process, 24.4ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 1 bus, 5 trucks, 7 traffic lights, 24.4ms\n",
            "Speed: 1.1ms pre-process, 24.4ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 1 bus, 5 trucks, 8 traffic lights, 24.4ms\n",
            "Speed: 1.0ms pre-process, 24.4ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 38 cars, 2 buss, 4 trucks, 7 traffic lights, 24.4ms\n",
            "Speed: 1.0ms pre-process, 24.4ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 1 bus, 6 trucks, 6 traffic lights, 24.5ms\n",
            "Speed: 1.1ms pre-process, 24.5ms inference, 2.1ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 2 buss, 3 trucks, 7 traffic lights, 24.9ms\n",
            "Speed: 1.0ms pre-process, 24.9ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 37 cars, 2 buss, 5 trucks, 6 traffic lights, 24.8ms\n",
            "Speed: 1.1ms pre-process, 24.8ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 39 cars, 2 buss, 5 trucks, 6 traffic lights, 25.2ms\n",
            "Speed: 1.0ms pre-process, 25.2ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 1 bus, 4 trucks, 6 traffic lights, 25.3ms\n",
            "Speed: 1.2ms pre-process, 25.3ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 1 bus, 5 trucks, 6 traffic lights, 25.3ms\n",
            "Speed: 1.1ms pre-process, 25.3ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 48 cars, 1 bus, 6 trucks, 6 traffic lights, 25.3ms\n",
            "Speed: 1.0ms pre-process, 25.3ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 48 cars, 1 bus, 6 trucks, 6 traffic lights, 25.4ms\n",
            "Speed: 1.4ms pre-process, 25.4ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 1 bus, 6 trucks, 5 traffic lights, 25.2ms\n",
            "Speed: 1.1ms pre-process, 25.2ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 1 bus, 6 trucks, 7 traffic lights, 25.2ms\n",
            "Speed: 1.0ms pre-process, 25.2ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 1 bus, 7 trucks, 7 traffic lights, 25.2ms\n",
            "Speed: 1.0ms pre-process, 25.2ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 5 trucks, 6 traffic lights, 25.3ms\n",
            "Speed: 0.9ms pre-process, 25.3ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 1 bus, 4 trucks, 6 traffic lights, 25.1ms\n",
            "Speed: 1.0ms pre-process, 25.1ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 2 buss, 5 trucks, 7 traffic lights, 25.4ms\n",
            "Speed: 1.0ms pre-process, 25.4ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 2 buss, 4 trucks, 6 traffic lights, 25.3ms\n",
            "Speed: 1.0ms pre-process, 25.3ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 2 buss, 6 trucks, 5 traffic lights, 25.2ms\n",
            "Speed: 1.1ms pre-process, 25.2ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 49 cars, 2 buss, 4 trucks, 5 traffic lights, 25.2ms\n",
            "Speed: 1.0ms pre-process, 25.2ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 2 buss, 4 trucks, 5 traffic lights, 25.2ms\n",
            "Speed: 1.1ms pre-process, 25.2ms inference, 2.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 1 bus, 5 trucks, 6 traffic lights, 25.2ms\n",
            "Speed: 1.2ms pre-process, 25.2ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 1 bus, 4 trucks, 6 traffic lights, 25.2ms\n",
            "Speed: 1.2ms pre-process, 25.2ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 2 buss, 8 trucks, 6 traffic lights, 25.2ms\n",
            "Speed: 1.0ms pre-process, 25.2ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 1 bus, 4 trucks, 7 traffic lights, 25.3ms\n",
            "Speed: 1.0ms pre-process, 25.3ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 1 bus, 4 trucks, 6 traffic lights, 25.2ms\n",
            "Speed: 1.1ms pre-process, 25.2ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 1 bus, 5 trucks, 6 traffic lights, 27.8ms\n",
            "Speed: 1.1ms pre-process, 27.8ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 40 cars, 1 bus, 6 trucks, 5 traffic lights, 25.1ms\n",
            "Speed: 1.0ms pre-process, 25.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 39 cars, 1 bus, 3 trucks, 6 traffic lights, 25.3ms\n",
            "Speed: 1.1ms pre-process, 25.3ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 2 buss, 5 trucks, 5 traffic lights, 25.2ms\n",
            "Speed: 1.2ms pre-process, 25.2ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 37 cars, 2 buss, 6 trucks, 6 traffic lights, 25.7ms\n",
            "Speed: 1.0ms pre-process, 25.7ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 38 cars, 7 trucks, 5 traffic lights, 25.3ms\n",
            "Speed: 1.0ms pre-process, 25.3ms inference, 2.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 1 bus, 7 trucks, 4 traffic lights, 25.2ms\n",
            "Speed: 1.1ms pre-process, 25.2ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 2 buss, 6 trucks, 4 traffic lights, 25.6ms\n",
            "Speed: 1.0ms pre-process, 25.6ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 51 cars, 3 buss, 5 trucks, 6 traffic lights, 25.5ms\n",
            "Speed: 1.1ms pre-process, 25.5ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 2 buss, 4 trucks, 7 traffic lights, 25.5ms\n",
            "Speed: 1.1ms pre-process, 25.5ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 1 bus, 6 trucks, 7 traffic lights, 25.6ms\n",
            "Speed: 1.0ms pre-process, 25.6ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 1 bus, 5 trucks, 7 traffic lights, 25.5ms\n",
            "Speed: 1.0ms pre-process, 25.5ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 2 buss, 7 trucks, 6 traffic lights, 25.7ms\n",
            "Speed: 1.1ms pre-process, 25.7ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 1 bus, 7 trucks, 8 traffic lights, 25.6ms\n",
            "Speed: 1.1ms pre-process, 25.6ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 2 buss, 6 trucks, 5 traffic lights, 26.2ms\n",
            "Speed: 1.2ms pre-process, 26.2ms inference, 4.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 37 cars, 2 buss, 6 trucks, 5 traffic lights, 25.6ms\n",
            "Speed: 1.0ms pre-process, 25.6ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 38 cars, 2 buss, 7 trucks, 6 traffic lights, 26.3ms\n",
            "Speed: 0.9ms pre-process, 26.3ms inference, 2.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 2 buss, 7 trucks, 4 traffic lights, 25.6ms\n",
            "Speed: 1.0ms pre-process, 25.6ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 2 buss, 5 trucks, 5 traffic lights, 25.7ms\n",
            "Speed: 1.0ms pre-process, 25.7ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 1 bus, 8 trucks, 4 traffic lights, 25.5ms\n",
            "Speed: 0.9ms pre-process, 25.5ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 1 bus, 7 trucks, 4 traffic lights, 25.7ms\n",
            "Speed: 1.0ms pre-process, 25.7ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 1 bus, 3 trucks, 5 traffic lights, 25.8ms\n",
            "Speed: 1.0ms pre-process, 25.8ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 1 bus, 2 trucks, 5 traffic lights, 26.0ms\n",
            "Speed: 1.0ms pre-process, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 4 trucks, 5 traffic lights, 26.1ms\n",
            "Speed: 1.0ms pre-process, 26.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 39 cars, 4 trucks, 6 traffic lights, 25.9ms\n",
            "Speed: 1.1ms pre-process, 25.9ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 39 cars, 4 trucks, 5 traffic lights, 26.0ms\n",
            "Speed: 1.1ms pre-process, 26.0ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 1 bus, 3 trucks, 6 traffic lights, 25.9ms\n",
            "Speed: 1.1ms pre-process, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 39 cars, 1 bus, 3 trucks, 6 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 4 trucks, 6 traffic lights, 26.0ms\n",
            "Speed: 1.1ms pre-process, 26.0ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 1 bus, 4 trucks, 6 traffic lights, 26.0ms\n",
            "Speed: 1.1ms pre-process, 26.0ms inference, 2.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 2 trucks, 5 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 5 traffic lights, 26.0ms\n",
            "Speed: 1.0ms pre-process, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 1 truck, 6 traffic lights, 25.9ms\n",
            "Speed: 1.1ms pre-process, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 3 trucks, 7 traffic lights, 26.1ms\n",
            "Speed: 1.0ms pre-process, 26.1ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 1 bus, 3 trucks, 6 traffic lights, 26.0ms\n",
            "Speed: 1.0ms pre-process, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 36 cars, 3 trucks, 7 traffic lights, 26.2ms\n",
            "Speed: 1.1ms pre-process, 26.2ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 39 cars, 1 bus, 2 trucks, 8 traffic lights, 26.0ms\n",
            "Speed: 1.0ms pre-process, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 1 bus, 2 trucks, 7 traffic lights, 26.0ms\n",
            "Speed: 1.1ms pre-process, 26.0ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 37 cars, 1 bus, 2 trucks, 5 traffic lights, 26.1ms\n",
            "Speed: 1.0ms pre-process, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 39 cars, 1 bus, 1 truck, 7 traffic lights, 26.0ms\n",
            "Speed: 1.1ms pre-process, 26.0ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 1 bus, 1 truck, 6 traffic lights, 25.8ms\n",
            "Speed: 0.9ms pre-process, 25.8ms inference, 3.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 1 bus, 1 truck, 7 traffic lights, 26.0ms\n",
            "Speed: 1.7ms pre-process, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 1 bus, 1 truck, 7 traffic lights, 25.9ms\n",
            "Speed: 1.1ms pre-process, 25.9ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 1 bus, 1 truck, 4 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 38 cars, 1 bus, 2 trucks, 5 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 1 bus, 1 truck, 6 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 1 bus, 6 traffic lights, 26.2ms\n",
            "Speed: 1.1ms pre-process, 26.2ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 37 cars, 1 bus, 1 truck, 5 traffic lights, 26.1ms\n",
            "Speed: 1.0ms pre-process, 26.1ms inference, 8.3ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 36 cars, 2 trucks, 6 traffic lights, 26.1ms\n",
            "Speed: 0.9ms pre-process, 26.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 1 truck, 7 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 2 trucks, 7 traffic lights, 26.4ms\n",
            "Speed: 1.1ms pre-process, 26.4ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 35 cars, 1 truck, 7 traffic lights, 26.3ms\n",
            "Speed: 1.0ms pre-process, 26.3ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 1 bus, 3 trucks, 6 traffic lights, 26.3ms\n",
            "Speed: 0.9ms pre-process, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 38 cars, 1 bus, 4 trucks, 6 traffic lights, 25.6ms\n",
            "Speed: 1.1ms pre-process, 25.6ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 1 bus, 4 trucks, 6 traffic lights, 25.2ms\n",
            "Speed: 1.1ms pre-process, 25.2ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 37 cars, 3 trucks, 6 traffic lights, 25.2ms\n",
            "Speed: 1.1ms pre-process, 25.2ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 2 trucks, 6 traffic lights, 25.7ms\n",
            "Speed: 1.0ms pre-process, 25.7ms inference, 2.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 39 cars, 1 bus, 2 trucks, 7 traffic lights, 25.2ms\n",
            "Speed: 1.1ms pre-process, 25.2ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 3 trucks, 8 traffic lights, 25.6ms\n",
            "Speed: 1.1ms pre-process, 25.6ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 1 bus, 4 trucks, 5 traffic lights, 25.3ms\n",
            "Speed: 1.1ms pre-process, 25.3ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 1 bus, 4 trucks, 4 traffic lights, 26.0ms\n",
            "Speed: 1.0ms pre-process, 26.0ms inference, 2.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 37 cars, 1 bus, 5 trucks, 5 traffic lights, 25.3ms\n",
            "Speed: 1.1ms pre-process, 25.3ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 39 cars, 1 bus, 4 trucks, 5 traffic lights, 25.2ms\n",
            "Speed: 1.1ms pre-process, 25.2ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 1 bus, 3 trucks, 4 traffic lights, 25.3ms\n",
            "Speed: 1.1ms pre-process, 25.3ms inference, 2.1ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 48 cars, 1 bus, 4 trucks, 5 traffic lights, 25.2ms\n",
            "Speed: 1.3ms pre-process, 25.2ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 1 bus, 6 trucks, 5 traffic lights, 25.1ms\n",
            "Speed: 1.0ms pre-process, 25.1ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 1 bus, 6 trucks, 4 traffic lights, 25.2ms\n",
            "Speed: 1.0ms pre-process, 25.2ms inference, 2.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 1 bus, 7 trucks, 5 traffic lights, 25.2ms\n",
            "Speed: 1.1ms pre-process, 25.2ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 1 bus, 5 trucks, 5 traffic lights, 25.2ms\n",
            "Speed: 1.0ms pre-process, 25.2ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 1 bus, 6 trucks, 5 traffic lights, 25.1ms\n",
            "Speed: 1.0ms pre-process, 25.1ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 36 cars, 1 bus, 7 trucks, 6 traffic lights, 25.2ms\n",
            "Speed: 1.0ms pre-process, 25.2ms inference, 4.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 7 trucks, 8 traffic lights, 26.6ms\n",
            "Speed: 1.1ms pre-process, 26.6ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 8 trucks, 7 traffic lights, 28.1ms\n",
            "Speed: 1.0ms pre-process, 28.1ms inference, 2.1ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 1 bus, 7 trucks, 5 traffic lights, 25.2ms\n",
            "Speed: 1.8ms pre-process, 25.2ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 1 bus, 6 trucks, 6 traffic lights, 25.2ms\n",
            "Speed: 1.1ms pre-process, 25.2ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 1 bus, 6 trucks, 5 traffic lights, 25.1ms\n",
            "Speed: 1.0ms pre-process, 25.1ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 37 cars, 1 bus, 8 trucks, 7 traffic lights, 27.3ms\n",
            "Speed: 1.0ms pre-process, 27.3ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 1 bus, 6 trucks, 6 traffic lights, 27.2ms\n",
            "Speed: 1.1ms pre-process, 27.2ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 1 bus, 5 trucks, 5 traffic lights, 27.7ms\n",
            "Speed: 1.0ms pre-process, 27.7ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 1 bus, 4 trucks, 6 traffic lights, 27.7ms\n",
            "Speed: 1.1ms pre-process, 27.7ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 1 bus, 6 trucks, 5 traffic lights, 28.2ms\n",
            "Speed: 1.1ms pre-process, 28.2ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 1 bus, 7 trucks, 6 traffic lights, 28.2ms\n",
            "Speed: 3.4ms pre-process, 28.2ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 1 bus, 5 trucks, 6 traffic lights, 30.2ms\n",
            "Speed: 1.1ms pre-process, 30.2ms inference, 6.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 48 cars, 4 trucks, 5 traffic lights, 28.4ms\n",
            "Speed: 1.1ms pre-process, 28.4ms inference, 2.1ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 1 bus, 5 trucks, 6 traffic lights, 28.2ms\n",
            "Speed: 1.0ms pre-process, 28.2ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 48 cars, 4 trucks, 7 traffic lights, 28.7ms\n",
            "Speed: 1.1ms pre-process, 28.7ms inference, 2.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 3 trucks, 6 traffic lights, 28.9ms\n",
            "Speed: 1.0ms pre-process, 28.9ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 2 trucks, 5 traffic lights, 29.4ms\n",
            "Speed: 1.0ms pre-process, 29.4ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 39 cars, 3 trucks, 7 traffic lights, 29.4ms\n",
            "Speed: 1.0ms pre-process, 29.4ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 5 trucks, 6 traffic lights, 35.3ms\n",
            "Speed: 1.1ms pre-process, 35.3ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 1 bus, 4 trucks, 7 traffic lights, 29.9ms\n",
            "Speed: 1.0ms pre-process, 29.9ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 1 bus, 4 trucks, 8 traffic lights, 34.8ms\n",
            "Speed: 1.1ms pre-process, 34.8ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 37 cars, 5 trucks, 5 traffic lights, 30.7ms\n",
            "Speed: 1.0ms pre-process, 30.7ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 39 cars, 4 trucks, 6 traffic lights, 30.6ms\n",
            "Speed: 1.0ms pre-process, 30.6ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 1 bus, 4 trucks, 5 traffic lights, 35.0ms\n",
            "Speed: 1.5ms pre-process, 35.0ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 5 trucks, 4 traffic lights, 30.5ms\n",
            "Speed: 1.0ms pre-process, 30.5ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 3 trucks, 5 traffic lights, 30.5ms\n",
            "Speed: 1.0ms pre-process, 30.5ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 3 trucks, 4 traffic lights, 30.5ms\n",
            "Speed: 1.0ms pre-process, 30.5ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 4 trucks, 4 traffic lights, 30.5ms\n",
            "Speed: 1.1ms pre-process, 30.5ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 4 trucks, 5 traffic lights, 30.6ms\n",
            "Speed: 1.0ms pre-process, 30.6ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 3 trucks, 5 traffic lights, 30.7ms\n",
            "Speed: 1.0ms pre-process, 30.7ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 3 trucks, 4 traffic lights, 30.6ms\n",
            "Speed: 3.1ms pre-process, 30.6ms inference, 2.1ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 52 cars, 4 trucks, 5 traffic lights, 30.6ms\n",
            "Speed: 1.1ms pre-process, 30.6ms inference, 2.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 4 trucks, 5 traffic lights, 30.5ms\n",
            "Speed: 1.0ms pre-process, 30.5ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 50 cars, 4 trucks, 5 traffic lights, 30.6ms\n",
            "Speed: 1.4ms pre-process, 30.6ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 6 trucks, 6 traffic lights, 29.4ms\n",
            "Speed: 1.1ms pre-process, 29.4ms inference, 2.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 5 trucks, 7 traffic lights, 29.6ms\n",
            "Speed: 1.1ms pre-process, 29.6ms inference, 2.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 8 trucks, 6 traffic lights, 34.2ms\n",
            "Speed: 1.1ms pre-process, 34.2ms inference, 2.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 37 cars, 7 trucks, 6 traffic lights, 29.3ms\n",
            "Speed: 1.0ms pre-process, 29.3ms inference, 2.1ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 7 trucks, 6 traffic lights, 29.3ms\n",
            "Speed: 1.1ms pre-process, 29.3ms inference, 2.1ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 6 trucks, 6 traffic lights, 29.3ms\n",
            "Speed: 1.0ms pre-process, 29.3ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 4 trucks, 6 traffic lights, 29.5ms\n",
            "Speed: 1.1ms pre-process, 29.5ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 3 trucks, 6 traffic lights, 29.3ms\n",
            "Speed: 1.0ms pre-process, 29.3ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 46 cars, 1 truck, 4 traffic lights, 29.3ms\n",
            "Speed: 1.0ms pre-process, 29.3ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 46 cars, 3 trucks, 5 traffic lights, 27.9ms\n",
            "Speed: 1.0ms pre-process, 27.9ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 45 cars, 5 trucks, 5 traffic lights, 27.6ms\n",
            "Speed: 1.0ms pre-process, 27.6ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 45 cars, 6 trucks, 6 traffic lights, 27.9ms\n",
            "Speed: 1.1ms pre-process, 27.9ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 40 cars, 4 trucks, 5 traffic lights, 26.9ms\n",
            "Speed: 1.1ms pre-process, 26.9ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 41 cars, 4 trucks, 6 traffic lights, 26.9ms\n",
            "Speed: 1.0ms pre-process, 26.9ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 51 cars, 3 trucks, 5 traffic lights, 26.8ms\n",
            "Speed: 1.1ms pre-process, 26.8ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 48 cars, 4 trucks, 5 traffic lights, 1 refrigerator, 26.1ms\n",
            "Speed: 1.0ms pre-process, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 44 cars, 3 trucks, 5 traffic lights, 26.2ms\n",
            "Speed: 1.0ms pre-process, 26.2ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 46 cars, 4 trucks, 5 traffic lights, 25.9ms\n",
            "Speed: 0.9ms pre-process, 25.9ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 40 cars, 1 bus, 2 trucks, 6 traffic lights, 26.1ms\n",
            "Speed: 1.0ms pre-process, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 43 cars, 2 buss, 2 trucks, 6 traffic lights, 25.9ms\n",
            "Speed: 0.9ms pre-process, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 49 cars, 2 buss, 2 trucks, 6 traffic lights, 26.0ms\n",
            "Speed: 1.2ms pre-process, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 47 cars, 1 bus, 2 trucks, 6 traffic lights, 26.2ms\n",
            "Speed: 1.1ms pre-process, 26.2ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 1 bus, 2 trucks, 6 traffic lights, 26.2ms\n",
            "Speed: 1.2ms pre-process, 26.2ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 1 bus, 3 trucks, 6 traffic lights, 26.0ms\n",
            "Speed: 1.0ms pre-process, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 3 buss, 7 trucks, 6 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 2 buss, 6 trucks, 6 traffic lights, 26.2ms\n",
            "Speed: 1.0ms pre-process, 26.2ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 35 cars, 2 buss, 3 trucks, 6 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 36 cars, 2 buss, 4 trucks, 7 traffic lights, 26.0ms\n",
            "Speed: 1.1ms pre-process, 26.0ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 30 cars, 2 buss, 6 trucks, 7 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 36 cars, 8 trucks, 7 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 35 cars, 2 buss, 6 trucks, 7 traffic lights, 26.0ms\n",
            "Speed: 1.0ms pre-process, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 33 cars, 1 bus, 6 trucks, 7 traffic lights, 26.0ms\n",
            "Speed: 1.1ms pre-process, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 36 cars, 2 buss, 5 trucks, 6 traffic lights, 26.1ms\n",
            "Speed: 1.0ms pre-process, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 36 cars, 1 bus, 5 trucks, 6 traffic lights, 26.4ms\n",
            "Speed: 1.1ms pre-process, 26.4ms inference, 3.3ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 32 cars, 6 trucks, 6 traffic lights, 26.2ms\n",
            "Speed: 1.1ms pre-process, 26.2ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 32 cars, 1 bus, 5 trucks, 5 traffic lights, 26.1ms\n",
            "Speed: 3.5ms pre-process, 26.1ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 34 cars, 6 trucks, 6 traffic lights, 26.1ms\n",
            "Speed: 1.2ms pre-process, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 34 cars, 7 trucks, 7 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 35 cars, 7 trucks, 6 traffic lights, 26.1ms\n",
            "Speed: 1.0ms pre-process, 26.1ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 42 cars, 6 trucks, 6 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 33 cars, 9 trucks, 6 traffic lights, 26.3ms\n",
            "Speed: 1.0ms pre-process, 26.3ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 36 cars, 6 trucks, 6 traffic lights, 26.4ms\n",
            "Speed: 1.0ms pre-process, 26.4ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 34 cars, 6 trucks, 6 traffic lights, 26.4ms\n",
            "Speed: 1.1ms pre-process, 26.4ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 34 cars, 6 trucks, 7 traffic lights, 26.4ms\n",
            "Speed: 1.1ms pre-process, 26.4ms inference, 2.3ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 31 cars, 6 trucks, 7 traffic lights, 26.6ms\n",
            "Speed: 1.1ms pre-process, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 30 cars, 6 trucks, 6 traffic lights, 26.5ms\n",
            "Speed: 1.0ms pre-process, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 32 cars, 6 trucks, 6 traffic lights, 26.7ms\n",
            "Speed: 1.1ms pre-process, 26.7ms inference, 3.3ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 37 cars, 1 bus, 5 trucks, 6 traffic lights, 26.4ms\n",
            "Speed: 1.0ms pre-process, 26.4ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 39 cars, 6 trucks, 6 traffic lights, 26.5ms\n",
            "Speed: 1.0ms pre-process, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 35 cars, 5 trucks, 6 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 34 cars, 6 trucks, 6 traffic lights, 26.1ms\n",
            "Speed: 1.2ms pre-process, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 37 cars, 6 trucks, 8 traffic lights, 26.2ms\n",
            "Speed: 1.1ms pre-process, 26.2ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 36 cars, 9 trucks, 6 traffic lights, 26.1ms\n",
            "Speed: 1.0ms pre-process, 26.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 35 cars, 8 trucks, 6 traffic lights, 26.0ms\n",
            "Speed: 1.1ms pre-process, 26.0ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 34 cars, 8 trucks, 6 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 38 cars, 8 trucks, 6 traffic lights, 25.9ms\n",
            "Speed: 1.1ms pre-process, 25.9ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 39 cars, 9 trucks, 6 traffic lights, 26.2ms\n",
            "Speed: 1.1ms pre-process, 26.2ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 39 cars, 7 trucks, 5 traffic lights, 26.1ms\n",
            "Speed: 1.0ms pre-process, 26.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 40 cars, 7 trucks, 7 traffic lights, 26.0ms\n",
            "Speed: 1.1ms pre-process, 26.0ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 42 cars, 7 trucks, 7 traffic lights, 26.0ms\n",
            "Speed: 1.0ms pre-process, 26.0ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 7 trucks, 6 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 6 trucks, 6 traffic lights, 26.1ms\n",
            "Speed: 1.0ms pre-process, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 46 cars, 5 trucks, 6 traffic lights, 26.2ms\n",
            "Speed: 1.1ms pre-process, 26.2ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 44 cars, 5 trucks, 6 traffic lights, 26.7ms\n",
            "Speed: 1.5ms pre-process, 26.7ms inference, 3.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 43 cars, 5 trucks, 7 traffic lights, 26.1ms\n",
            "Speed: 1.0ms pre-process, 26.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 5 trucks, 7 traffic lights, 26.1ms\n",
            "Speed: 1.3ms pre-process, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 4 trucks, 7 traffic lights, 26.2ms\n",
            "Speed: 1.1ms pre-process, 26.2ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 45 cars, 4 trucks, 7 traffic lights, 26.2ms\n",
            "Speed: 1.1ms pre-process, 26.2ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 4 trucks, 6 traffic lights, 26.3ms\n",
            "Speed: 1.4ms pre-process, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 3 trucks, 6 traffic lights, 26.9ms\n",
            "Speed: 1.0ms pre-process, 26.9ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 5 trucks, 6 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 4 trucks, 6 traffic lights, 26.8ms\n",
            "Speed: 1.1ms pre-process, 26.8ms inference, 2.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 48 cars, 4 trucks, 6 traffic lights, 26.0ms\n",
            "Speed: 1.1ms pre-process, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 51 cars, 4 trucks, 6 traffic lights, 26.0ms\n",
            "Speed: 1.0ms pre-process, 26.0ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 58 cars, 3 trucks, 6 traffic lights, 26.4ms\n",
            "Speed: 1.1ms pre-process, 26.4ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 52 cars, 4 trucks, 6 traffic lights, 26.6ms\n",
            "Speed: 1.1ms pre-process, 26.6ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 55 cars, 4 trucks, 7 traffic lights, 26.4ms\n",
            "Speed: 1.1ms pre-process, 26.4ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 5 trucks, 6 traffic lights, 26.4ms\n",
            "Speed: 1.2ms pre-process, 26.4ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 5 trucks, 6 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 50 cars, 4 trucks, 6 traffic lights, 25.9ms\n",
            "Speed: 1.1ms pre-process, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 52 cars, 3 trucks, 6 traffic lights, 26.3ms\n",
            "Speed: 1.1ms pre-process, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 3 trucks, 5 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 4 trucks, 5 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 4 trucks, 5 traffic lights, 26.0ms\n",
            "Speed: 1.1ms pre-process, 26.0ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 4 trucks, 7 traffic lights, 26.1ms\n",
            "Speed: 1.0ms pre-process, 26.1ms inference, 2.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 48 cars, 3 trucks, 7 traffic lights, 26.1ms\n",
            "Speed: 0.9ms pre-process, 26.1ms inference, 2.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 3 trucks, 6 traffic lights, 25.9ms\n",
            "Speed: 1.1ms pre-process, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 4 trucks, 8 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 5 trucks, 7 traffic lights, 26.0ms\n",
            "Speed: 1.1ms pre-process, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 5 trucks, 7 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 53 cars, 5 trucks, 8 traffic lights, 26.3ms\n",
            "Speed: 1.1ms pre-process, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 53 cars, 4 trucks, 7 traffic lights, 25.9ms\n",
            "Speed: 1.1ms pre-process, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 56 cars, 3 trucks, 7 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 56 cars, 3 trucks, 6 traffic lights, 26.2ms\n",
            "Speed: 1.1ms pre-process, 26.2ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 51 cars, 4 trucks, 7 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 50 cars, 4 trucks, 7 traffic lights, 26.5ms\n",
            "Speed: 1.0ms pre-process, 26.5ms inference, 2.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 51 cars, 3 trucks, 7 traffic lights, 25.9ms\n",
            "Speed: 1.3ms pre-process, 25.9ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 3 trucks, 7 traffic lights, 26.0ms\n",
            "Speed: 1.0ms pre-process, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 53 cars, 3 trucks, 7 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 55 cars, 3 trucks, 7 traffic lights, 26.1ms\n",
            "Speed: 1.0ms pre-process, 26.1ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 3 trucks, 7 traffic lights, 25.9ms\n",
            "Speed: 1.1ms pre-process, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 49 cars, 3 trucks, 6 traffic lights, 26.9ms\n",
            "Speed: 1.0ms pre-process, 26.9ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 54 cars, 3 trucks, 6 traffic lights, 26.0ms\n",
            "Speed: 0.9ms pre-process, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 50 cars, 3 trucks, 5 traffic lights, 26.1ms\n",
            "Speed: 1.0ms pre-process, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 50 cars, 4 trucks, 5 traffic lights, 25.9ms\n",
            "Speed: 1.1ms pre-process, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 55 cars, 3 trucks, 5 traffic lights, 25.9ms\n",
            "Speed: 1.2ms pre-process, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 50 cars, 3 trucks, 5 traffic lights, 26.3ms\n",
            "Speed: 1.2ms pre-process, 26.3ms inference, 3.1ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 52 cars, 4 trucks, 6 traffic lights, 26.6ms\n",
            "Speed: 1.1ms pre-process, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 56 cars, 4 trucks, 6 traffic lights, 25.9ms\n",
            "Speed: 0.9ms pre-process, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 51 cars, 5 trucks, 7 traffic lights, 25.9ms\n",
            "Speed: 1.1ms pre-process, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 5 trucks, 6 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 50 cars, 5 trucks, 8 traffic lights, 26.0ms\n",
            "Speed: 0.9ms pre-process, 26.0ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 48 cars, 6 trucks, 6 traffic lights, 26.1ms\n",
            "Speed: 1.6ms pre-process, 26.1ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 6 trucks, 7 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 6 trucks, 7 traffic lights, 25.8ms\n",
            "Speed: 1.1ms pre-process, 25.8ms inference, 3.1ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 49 cars, 7 trucks, 7 traffic lights, 25.3ms\n",
            "Speed: 9.4ms pre-process, 25.3ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 55 cars, 6 trucks, 7 traffic lights, 25.3ms\n",
            "Speed: 1.0ms pre-process, 25.3ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 48 cars, 6 trucks, 8 traffic lights, 25.3ms\n",
            "Speed: 1.3ms pre-process, 25.3ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 6 trucks, 6 traffic lights, 25.2ms\n",
            "Speed: 1.1ms pre-process, 25.2ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 50 cars, 6 trucks, 7 traffic lights, 25.2ms\n",
            "Speed: 1.1ms pre-process, 25.2ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 39 cars, 7 trucks, 6 traffic lights, 25.1ms\n",
            "Speed: 1.1ms pre-process, 25.1ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 6 trucks, 6 traffic lights, 25.1ms\n",
            "Speed: 1.0ms pre-process, 25.1ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 49 cars, 6 trucks, 8 traffic lights, 25.1ms\n",
            "Speed: 1.0ms pre-process, 25.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 50 cars, 7 trucks, 7 traffic lights, 25.2ms\n",
            "Speed: 1.1ms pre-process, 25.2ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 50 cars, 6 trucks, 8 traffic lights, 25.2ms\n",
            "Speed: 1.1ms pre-process, 25.2ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 8 trucks, 8 traffic lights, 25.1ms\n",
            "Speed: 0.9ms pre-process, 25.1ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 8 trucks, 8 traffic lights, 25.2ms\n",
            "Speed: 1.1ms pre-process, 25.2ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 7 trucks, 7 traffic lights, 25.1ms\n",
            "Speed: 1.1ms pre-process, 25.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 6 trucks, 8 traffic lights, 25.1ms\n",
            "Speed: 1.0ms pre-process, 25.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 60 cars, 9 trucks, 8 traffic lights, 25.1ms\n",
            "Speed: 1.1ms pre-process, 25.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 11 trucks, 7 traffic lights, 25.1ms\n",
            "Speed: 1.0ms pre-process, 25.1ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 49 cars, 4 trucks, 7 traffic lights, 25.4ms\n",
            "Speed: 1.0ms pre-process, 25.4ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 49 cars, 6 trucks, 8 traffic lights, 25.3ms\n",
            "Speed: 1.0ms pre-process, 25.3ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 6 trucks, 9 traffic lights, 25.3ms\n",
            "Speed: 1.1ms pre-process, 25.3ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 7 trucks, 9 traffic lights, 25.3ms\n",
            "Speed: 1.0ms pre-process, 25.3ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 1 bus, 5 trucks, 6 traffic lights, 25.3ms\n",
            "Speed: 1.0ms pre-process, 25.3ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 49 cars, 5 trucks, 6 traffic lights, 25.3ms\n",
            "Speed: 1.1ms pre-process, 25.3ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 6 trucks, 6 traffic lights, 25.3ms\n",
            "Speed: 1.1ms pre-process, 25.3ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 6 trucks, 4 traffic lights, 25.2ms\n",
            "Speed: 1.3ms pre-process, 25.2ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 5 trucks, 5 traffic lights, 25.1ms\n",
            "Speed: 0.9ms pre-process, 25.1ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 48 cars, 6 trucks, 4 traffic lights, 25.3ms\n",
            "Speed: 1.0ms pre-process, 25.3ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 6 trucks, 5 traffic lights, 25.8ms\n",
            "Speed: 1.1ms pre-process, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 5 trucks, 6 traffic lights, 25.6ms\n",
            "Speed: 1.1ms pre-process, 25.6ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 49 cars, 5 trucks, 6 traffic lights, 25.6ms\n",
            "Speed: 1.1ms pre-process, 25.6ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 49 cars, 5 trucks, 7 traffic lights, 25.6ms\n",
            "Speed: 1.1ms pre-process, 25.6ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 6 trucks, 7 traffic lights, 25.7ms\n",
            "Speed: 1.1ms pre-process, 25.7ms inference, 2.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 5 trucks, 6 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 49 cars, 6 trucks, 7 traffic lights, 26.2ms\n",
            "Speed: 1.1ms pre-process, 26.2ms inference, 2.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 6 trucks, 9 traffic lights, 26.0ms\n",
            "Speed: 1.2ms pre-process, 26.0ms inference, 2.1ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 53 cars, 6 trucks, 8 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 2.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 5 trucks, 8 traffic lights, 28.4ms\n",
            "Speed: 1.0ms pre-process, 28.4ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 4 trucks, 6 traffic lights, 26.8ms\n",
            "Speed: 1.6ms pre-process, 26.8ms inference, 2.3ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 6 trucks, 6 traffic lights, 26.8ms\n",
            "Speed: 1.0ms pre-process, 26.8ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 5 trucks, 7 traffic lights, 26.9ms\n",
            "Speed: 1.7ms pre-process, 26.9ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 5 trucks, 7 traffic lights, 26.8ms\n",
            "Speed: 7.6ms pre-process, 26.8ms inference, 2.3ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 5 trucks, 7 traffic lights, 26.8ms\n",
            "Speed: 1.0ms pre-process, 26.8ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 51 cars, 5 trucks, 7 traffic lights, 27.3ms\n",
            "Speed: 1.0ms pre-process, 27.3ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 50 cars, 5 trucks, 7 traffic lights, 32.2ms\n",
            "Speed: 1.1ms pre-process, 32.2ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 48 cars, 5 trucks, 9 traffic lights, 32.1ms\n",
            "Speed: 1.0ms pre-process, 32.1ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 48 cars, 4 trucks, 8 traffic lights, 29.4ms\n",
            "Speed: 1.0ms pre-process, 29.4ms inference, 2.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 4 trucks, 8 traffic lights, 32.6ms\n",
            "Speed: 1.1ms pre-process, 32.6ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 6 trucks, 8 traffic lights, 28.4ms\n",
            "Speed: 1.0ms pre-process, 28.4ms inference, 2.3ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 5 trucks, 7 traffic lights, 31.0ms\n",
            "Speed: 1.0ms pre-process, 31.0ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 4 trucks, 7 traffic lights, 28.9ms\n",
            "Speed: 4.2ms pre-process, 28.9ms inference, 2.1ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 5 trucks, 7 traffic lights, 29.3ms\n",
            "Speed: 1.0ms pre-process, 29.3ms inference, 2.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 5 trucks, 7 traffic lights, 29.4ms\n",
            "Speed: 1.1ms pre-process, 29.4ms inference, 4.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 5 trucks, 7 traffic lights, 30.0ms\n",
            "Speed: 1.1ms pre-process, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 48 cars, 6 trucks, 7 traffic lights, 29.9ms\n",
            "Speed: 1.4ms pre-process, 29.9ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 7 trucks, 6 traffic lights, 32.4ms\n",
            "Speed: 1.1ms pre-process, 32.4ms inference, 2.1ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 6 trucks, 5 traffic lights, 30.5ms\n",
            "Speed: 1.0ms pre-process, 30.5ms inference, 2.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 9 trucks, 6 traffic lights, 30.6ms\n",
            "Speed: 1.0ms pre-process, 30.6ms inference, 2.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 6 trucks, 6 traffic lights, 31.6ms\n",
            "Speed: 1.0ms pre-process, 31.6ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 7 trucks, 7 traffic lights, 30.5ms\n",
            "Speed: 1.0ms pre-process, 30.5ms inference, 2.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 48 cars, 8 trucks, 6 traffic lights, 32.7ms\n",
            "Speed: 1.1ms pre-process, 32.7ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 49 cars, 8 trucks, 6 traffic lights, 30.5ms\n",
            "Speed: 1.0ms pre-process, 30.5ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 50 cars, 7 trucks, 6 traffic lights, 30.5ms\n",
            "Speed: 1.7ms pre-process, 30.5ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 49 cars, 7 trucks, 6 traffic lights, 30.5ms\n",
            "Speed: 1.0ms pre-process, 30.5ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 9 trucks, 6 traffic lights, 30.5ms\n",
            "Speed: 1.1ms pre-process, 30.5ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 8 trucks, 7 traffic lights, 32.4ms\n",
            "Speed: 1.0ms pre-process, 32.4ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 9 trucks, 6 traffic lights, 31.6ms\n",
            "Speed: 1.1ms pre-process, 31.6ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 6 trucks, 6 traffic lights, 30.5ms\n",
            "Speed: 1.0ms pre-process, 30.5ms inference, 2.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 48 cars, 7 trucks, 7 traffic lights, 30.5ms\n",
            "Speed: 1.0ms pre-process, 30.5ms inference, 2.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 6 trucks, 5 traffic lights, 30.6ms\n",
            "Speed: 1.0ms pre-process, 30.6ms inference, 5.3ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 8 trucks, 5 traffic lights, 30.7ms\n",
            "Speed: 1.1ms pre-process, 30.7ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 6 trucks, 6 traffic lights, 30.5ms\n",
            "Speed: 1.1ms pre-process, 30.5ms inference, 2.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 49 cars, 6 trucks, 5 traffic lights, 30.8ms\n",
            "Speed: 1.7ms pre-process, 30.8ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 8 trucks, 5 traffic lights, 30.6ms\n",
            "Speed: 2.0ms pre-process, 30.6ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 10 trucks, 6 traffic lights, 30.5ms\n",
            "Speed: 1.0ms pre-process, 30.5ms inference, 2.1ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 48 cars, 5 trucks, 5 traffic lights, 30.6ms\n",
            "Speed: 1.1ms pre-process, 30.6ms inference, 2.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 51 cars, 1 bus, 5 trucks, 5 traffic lights, 30.7ms\n",
            "Speed: 1.2ms pre-process, 30.7ms inference, 2.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 6 trucks, 6 traffic lights, 32.6ms\n",
            "Speed: 1.1ms pre-process, 32.6ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 7 trucks, 6 traffic lights, 30.6ms\n",
            "Speed: 1.1ms pre-process, 30.6ms inference, 3.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 48 cars, 5 trucks, 8 traffic lights, 30.5ms\n",
            "Speed: 1.1ms pre-process, 30.5ms inference, 2.3ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 7 trucks, 7 traffic lights, 30.7ms\n",
            "Speed: 1.7ms pre-process, 30.7ms inference, 2.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 7 trucks, 7 traffic lights, 30.6ms\n",
            "Speed: 1.2ms pre-process, 30.6ms inference, 2.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 6 trucks, 6 traffic lights, 30.6ms\n",
            "Speed: 1.1ms pre-process, 30.6ms inference, 2.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 3 trucks, 5 traffic lights, 30.5ms\n",
            "Speed: 1.1ms pre-process, 30.5ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 2 trucks, 7 traffic lights, 30.5ms\n",
            "Speed: 1.1ms pre-process, 30.5ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 4 trucks, 5 traffic lights, 30.4ms\n",
            "Speed: 1.1ms pre-process, 30.4ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 51 cars, 4 trucks, 6 traffic lights, 28.5ms\n",
            "Speed: 1.1ms pre-process, 28.5ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 49 cars, 1 truck, 5 traffic lights, 28.6ms\n",
            "Speed: 1.1ms pre-process, 28.6ms inference, 2.1ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 1 truck, 5 traffic lights, 28.3ms\n",
            "Speed: 1.4ms pre-process, 28.3ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 4 trucks, 6 traffic lights, 28.3ms\n",
            "Speed: 1.0ms pre-process, 28.3ms inference, 2.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 3 trucks, 6 traffic lights, 28.5ms\n",
            "Speed: 1.1ms pre-process, 28.5ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 42 cars, 2 trucks, 6 traffic lights, 1 refrigerator, 26.5ms\n",
            "Speed: 1.0ms pre-process, 26.5ms inference, 2.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 3 trucks, 5 traffic lights, 26.5ms\n",
            "Speed: 1.0ms pre-process, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 3 trucks, 5 traffic lights, 26.5ms\n",
            "Speed: 1.1ms pre-process, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 3 trucks, 5 traffic lights, 26.0ms\n",
            "Speed: 1.1ms pre-process, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 3 trucks, 7 traffic lights, 26.1ms\n",
            "Speed: 1.0ms pre-process, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 3 trucks, 6 traffic lights, 26.2ms\n",
            "Speed: 1.1ms pre-process, 26.2ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 49 cars, 3 trucks, 5 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 4 trucks, 5 traffic lights, 26.2ms\n",
            "Speed: 1.1ms pre-process, 26.2ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 5 trucks, 5 traffic lights, 26.1ms\n",
            "Speed: 1.0ms pre-process, 26.1ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 3 trucks, 5 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 4 trucks, 5 traffic lights, 26.0ms\n",
            "Speed: 1.0ms pre-process, 26.0ms inference, 2.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 4 trucks, 6 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 48 cars, 3 trucks, 7 traffic lights, 25.9ms\n",
            "Speed: 1.1ms pre-process, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 38 cars, 4 trucks, 5 traffic lights, 26.0ms\n",
            "Speed: 1.0ms pre-process, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 50 cars, 5 trucks, 5 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 45 cars, 4 trucks, 6 traffic lights, 26.0ms\n",
            "Speed: 1.0ms pre-process, 26.0ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 42 cars, 4 trucks, 6 traffic lights, 26.1ms\n",
            "Speed: 1.0ms pre-process, 26.1ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 38 cars, 5 trucks, 6 traffic lights, 26.1ms\n",
            "Speed: 1.0ms pre-process, 26.1ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 4 trucks, 6 traffic lights, 26.0ms\n",
            "Speed: 1.0ms pre-process, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 4 trucks, 8 traffic lights, 26.0ms\n",
            "Speed: 1.1ms pre-process, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 5 trucks, 7 traffic lights, 26.1ms\n",
            "Speed: 1.2ms pre-process, 26.1ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 36 cars, 4 trucks, 7 traffic lights, 26.4ms\n",
            "Speed: 1.0ms pre-process, 26.4ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 40 cars, 4 trucks, 8 traffic lights, 26.1ms\n",
            "Speed: 1.0ms pre-process, 26.1ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 37 cars, 4 trucks, 9 traffic lights, 26.8ms\n",
            "Speed: 1.1ms pre-process, 26.8ms inference, 2.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 5 trucks, 6 traffic lights, 26.2ms\n",
            "Speed: 1.9ms pre-process, 26.2ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 4 trucks, 7 traffic lights, 26.0ms\n",
            "Speed: 1.0ms pre-process, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 5 trucks, 8 traffic lights, 26.6ms\n",
            "Speed: 1.0ms pre-process, 26.6ms inference, 2.1ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 5 trucks, 5 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 4 trucks, 6 traffic lights, 26.2ms\n",
            "Speed: 1.1ms pre-process, 26.2ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 5 trucks, 7 traffic lights, 26.0ms\n",
            "Speed: 1.0ms pre-process, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 5 trucks, 5 traffic lights, 25.9ms\n",
            "Speed: 1.1ms pre-process, 25.9ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 7 trucks, 5 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 38 cars, 7 trucks, 6 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 9 trucks, 5 traffic lights, 25.9ms\n",
            "Speed: 1.1ms pre-process, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 38 cars, 1 bus, 7 trucks, 7 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 37 cars, 7 trucks, 7 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 7 trucks, 7 traffic lights, 26.5ms\n",
            "Speed: 0.9ms pre-process, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 42 cars, 7 trucks, 7 traffic lights, 26.4ms\n",
            "Speed: 1.0ms pre-process, 26.4ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 45 cars, 6 trucks, 9 traffic lights, 26.4ms\n",
            "Speed: 1.0ms pre-process, 26.4ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 42 cars, 7 trucks, 6 traffic lights, 26.2ms\n",
            "Speed: 1.1ms pre-process, 26.2ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 8 trucks, 8 traffic lights, 26.0ms\n",
            "Speed: 1.1ms pre-process, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 8 trucks, 7 traffic lights, 26.2ms\n",
            "Speed: 1.0ms pre-process, 26.2ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 7 trucks, 5 traffic lights, 26.1ms\n",
            "Speed: 1.0ms pre-process, 26.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 8 trucks, 6 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 10 trucks, 4 traffic lights, 26.0ms\n",
            "Speed: 1.1ms pre-process, 26.0ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 46 cars, 6 trucks, 5 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 49 cars, 10 trucks, 5 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 7 trucks, 4 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 6 trucks, 4 traffic lights, 25.9ms\n",
            "Speed: 1.2ms pre-process, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 50 cars, 5 trucks, 4 traffic lights, 26.2ms\n",
            "Speed: 1.1ms pre-process, 26.2ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 6 trucks, 4 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 1 bus, 5 trucks, 4 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 44 cars, 5 trucks, 4 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 7 trucks, 4 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 5 trucks, 5 traffic lights, 26.1ms\n",
            "Speed: 1.0ms pre-process, 26.1ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 7 trucks, 5 traffic lights, 26.0ms\n",
            "Speed: 0.9ms pre-process, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 1 bus, 6 trucks, 5 traffic lights, 25.9ms\n",
            "Speed: 1.1ms pre-process, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 6 trucks, 6 traffic lights, 26.0ms\n",
            "Speed: 1.1ms pre-process, 26.0ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 6 trucks, 6 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 6 trucks, 5 traffic lights, 26.0ms\n",
            "Speed: 1.5ms pre-process, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 5 trucks, 5 traffic lights, 26.2ms\n",
            "Speed: 1.1ms pre-process, 26.2ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 41 cars, 6 trucks, 5 traffic lights, 26.3ms\n",
            "Speed: 1.2ms pre-process, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 40 cars, 5 trucks, 6 traffic lights, 26.0ms\n",
            "Speed: 1.0ms pre-process, 26.0ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 42 cars, 5 trucks, 5 traffic lights, 25.9ms\n",
            "Speed: 1.1ms pre-process, 25.9ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 40 cars, 6 trucks, 6 traffic lights, 25.9ms\n",
            "Speed: 1.1ms pre-process, 25.9ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 43 cars, 6 trucks, 6 traffic lights, 25.9ms\n",
            "Speed: 1.1ms pre-process, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 40 cars, 5 trucks, 6 traffic lights, 25.9ms\n",
            "Speed: 1.3ms pre-process, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 39 cars, 6 trucks, 6 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 40 cars, 7 trucks, 6 traffic lights, 25.9ms\n",
            "Speed: 1.1ms pre-process, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 40 cars, 7 trucks, 6 traffic lights, 26.0ms\n",
            "Speed: 1.1ms pre-process, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 38 cars, 8 trucks, 6 traffic lights, 26.0ms\n",
            "Speed: 1.0ms pre-process, 26.0ms inference, 2.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 41 cars, 6 trucks, 6 traffic lights, 26.0ms\n",
            "Speed: 1.0ms pre-process, 26.0ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 42 cars, 6 trucks, 6 traffic lights, 25.9ms\n",
            "Speed: 3.9ms pre-process, 25.9ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 44 cars, 5 trucks, 6 traffic lights, 26.3ms\n",
            "Speed: 1.1ms pre-process, 26.3ms inference, 2.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 39 cars, 6 trucks, 6 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 44 cars, 5 trucks, 5 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 43 cars, 5 trucks, 6 traffic lights, 26.2ms\n",
            "Speed: 1.1ms pre-process, 26.2ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 6 trucks, 7 traffic lights, 26.2ms\n",
            "Speed: 1.3ms pre-process, 26.2ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 5 trucks, 7 traffic lights, 1 toilet, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 42 cars, 4 trucks, 7 traffic lights, 25.9ms\n",
            "Speed: 1.1ms pre-process, 25.9ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 43 cars, 7 trucks, 7 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 43 cars, 6 trucks, 7 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 2 persons, 46 cars, 5 trucks, 7 traffic lights, 26.5ms\n",
            "Speed: 1.0ms pre-process, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 48 cars, 6 trucks, 7 traffic lights, 26.8ms\n",
            "Speed: 1.2ms pre-process, 26.8ms inference, 3.3ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 7 trucks, 6 traffic lights, 26.5ms\n",
            "Speed: 1.0ms pre-process, 26.5ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 52 cars, 6 trucks, 6 traffic lights, 26.4ms\n",
            "Speed: 6.2ms pre-process, 26.4ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 51 cars, 7 trucks, 6 traffic lights, 27.3ms\n",
            "Speed: 1.1ms pre-process, 27.3ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 48 cars, 9 trucks, 7 traffic lights, 26.3ms\n",
            "Speed: 1.2ms pre-process, 26.3ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 10 trucks, 6 traffic lights, 25.9ms\n",
            "Speed: 1.2ms pre-process, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 50 cars, 9 trucks, 5 traffic lights, 25.9ms\n",
            "Speed: 1.1ms pre-process, 25.9ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 10 trucks, 6 traffic lights, 26.1ms\n",
            "Speed: 0.9ms pre-process, 26.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 11 trucks, 6 traffic lights, 26.0ms\n",
            "Speed: 1.0ms pre-process, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 11 trucks, 6 traffic lights, 26.3ms\n",
            "Speed: 1.0ms pre-process, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 56 cars, 9 trucks, 7 traffic lights, 25.9ms\n",
            "Speed: 1.1ms pre-process, 25.9ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 8 trucks, 8 traffic lights, 26.4ms\n",
            "Speed: 1.0ms pre-process, 26.4ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 7 trucks, 6 traffic lights, 26.1ms\n",
            "Speed: 1.0ms pre-process, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 9 trucks, 6 traffic lights, 26.1ms\n",
            "Speed: 1.2ms pre-process, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 50 cars, 8 trucks, 6 traffic lights, 26.3ms\n",
            "Speed: 1.3ms pre-process, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 49 cars, 10 trucks, 7 traffic lights, 26.2ms\n",
            "Speed: 1.1ms pre-process, 26.2ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 50 cars, 11 trucks, 8 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 8 trucks, 7 traffic lights, 26.0ms\n",
            "Speed: 1.1ms pre-process, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 50 cars, 6 trucks, 7 traffic lights, 26.1ms\n",
            "Speed: 1.0ms pre-process, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 6 trucks, 8 traffic lights, 25.9ms\n",
            "Speed: 1.1ms pre-process, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 7 trucks, 7 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 8 trucks, 7 traffic lights, 26.1ms\n",
            "Speed: 1.0ms pre-process, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 6 trucks, 8 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 7 trucks, 7 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 48 cars, 7 trucks, 7 traffic lights, 30.7ms\n",
            "Speed: 1.0ms pre-process, 30.7ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 7 trucks, 7 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 7 trucks, 7 traffic lights, 25.9ms\n",
            "Speed: 1.1ms pre-process, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 1 bus, 6 trucks, 7 traffic lights, 26.1ms\n",
            "Speed: 1.2ms pre-process, 26.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 48 cars, 5 trucks, 6 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 4 trucks, 6 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 49 cars, 4 trucks, 6 traffic lights, 26.4ms\n",
            "Speed: 1.0ms pre-process, 26.4ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 48 cars, 2 trucks, 6 traffic lights, 26.5ms\n",
            "Speed: 0.9ms pre-process, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 49 cars, 2 trucks, 6 traffic lights, 26.4ms\n",
            "Speed: 1.1ms pre-process, 26.4ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 50 cars, 4 trucks, 5 traffic lights, 26.3ms\n",
            "Speed: 1.0ms pre-process, 26.3ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 2 trucks, 6 traffic lights, 26.5ms\n",
            "Speed: 1.1ms pre-process, 26.5ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 4 trucks, 6 traffic lights, 26.6ms\n",
            "Speed: 1.0ms pre-process, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 49 cars, 5 trucks, 6 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 52 cars, 4 trucks, 6 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 3 trucks, 7 traffic lights, 26.2ms\n",
            "Speed: 1.1ms pre-process, 26.2ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 4 trucks, 7 traffic lights, 26.0ms\n",
            "Speed: 0.9ms pre-process, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 6 trucks, 6 traffic lights, 26.0ms\n",
            "Speed: 1.0ms pre-process, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 39 cars, 3 trucks, 7 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 37 cars, 3 trucks, 6 traffic lights, 26.2ms\n",
            "Speed: 1.2ms pre-process, 26.2ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 3 trucks, 6 traffic lights, 26.0ms\n",
            "Speed: 1.1ms pre-process, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 3 trucks, 6 traffic lights, 26.0ms\n",
            "Speed: 1.0ms pre-process, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 3 trucks, 6 traffic lights, 26.0ms\n",
            "Speed: 1.5ms pre-process, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 53 cars, 3 trucks, 7 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 2.1ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 53 cars, 4 trucks, 6 traffic lights, 26.0ms\n",
            "Speed: 1.2ms pre-process, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 51 cars, 4 trucks, 6 traffic lights, 26.2ms\n",
            "Speed: 1.0ms pre-process, 26.2ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 48 cars, 4 trucks, 6 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 4 trucks, 6 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 4 trucks, 6 traffic lights, 26.0ms\n",
            "Speed: 1.0ms pre-process, 26.0ms inference, 2.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 4 trucks, 6 traffic lights, 26.5ms\n",
            "Speed: 1.0ms pre-process, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 39 cars, 4 trucks, 6 traffic lights, 26.0ms\n",
            "Speed: 1.1ms pre-process, 26.0ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 4 trucks, 6 traffic lights, 26.8ms\n",
            "Speed: 1.0ms pre-process, 26.8ms inference, 2.1ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 4 trucks, 6 traffic lights, 26.1ms\n",
            "Speed: 1.0ms pre-process, 26.1ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 35 cars, 4 trucks, 7 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 4 trucks, 7 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 39 cars, 4 trucks, 7 traffic lights, 27.8ms\n",
            "Speed: 1.1ms pre-process, 27.8ms inference, 2.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 6 trucks, 8 traffic lights, 29.0ms\n",
            "Speed: 1.0ms pre-process, 29.0ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 39 cars, 6 trucks, 7 traffic lights, 27.3ms\n",
            "Speed: 1.1ms pre-process, 27.3ms inference, 2.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 1 bus, 4 trucks, 6 traffic lights, 27.7ms\n",
            "Speed: 1.0ms pre-process, 27.7ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 7 trucks, 7 traffic lights, 28.3ms\n",
            "Speed: 1.0ms pre-process, 28.3ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 5 trucks, 7 traffic lights, 28.5ms\n",
            "Speed: 1.1ms pre-process, 28.5ms inference, 2.1ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 6 trucks, 7 traffic lights, 28.8ms\n",
            "Speed: 1.1ms pre-process, 28.8ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 5 trucks, 7 traffic lights, 33.5ms\n",
            "Speed: 1.1ms pre-process, 33.5ms inference, 2.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 4 trucks, 7 traffic lights, 29.4ms\n",
            "Speed: 1.1ms pre-process, 29.4ms inference, 2.3ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 3 trucks, 7 traffic lights, 29.5ms\n",
            "Speed: 4.3ms pre-process, 29.5ms inference, 2.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 1 bus, 5 trucks, 7 traffic lights, 29.6ms\n",
            "Speed: 1.0ms pre-process, 29.6ms inference, 2.1ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 3 trucks, 6 traffic lights, 30.1ms\n",
            "Speed: 1.1ms pre-process, 30.1ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 3 trucks, 7 traffic lights, 1 refrigerator, 30.8ms\n",
            "Speed: 1.1ms pre-process, 30.8ms inference, 4.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 5 trucks, 6 traffic lights, 1 refrigerator, 30.5ms\n",
            "Speed: 1.0ms pre-process, 30.5ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 5 trucks, 7 traffic lights, 30.5ms\n",
            "Speed: 2.0ms pre-process, 30.5ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 5 trucks, 6 traffic lights, 30.8ms\n",
            "Speed: 1.1ms pre-process, 30.8ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 5 trucks, 7 traffic lights, 30.7ms\n",
            "Speed: 1.2ms pre-process, 30.7ms inference, 2.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 6 trucks, 6 traffic lights, 30.6ms\n",
            "Speed: 1.1ms pre-process, 30.6ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 38 cars, 6 trucks, 6 traffic lights, 28.2ms\n",
            "Speed: 1.0ms pre-process, 28.2ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 36 cars, 7 trucks, 9 traffic lights, 28.4ms\n",
            "Speed: 1.1ms pre-process, 28.4ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 7 trucks, 8 traffic lights, 28.3ms\n",
            "Speed: 1.1ms pre-process, 28.3ms inference, 2.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 5 trucks, 9 traffic lights, 28.9ms\n",
            "Speed: 1.0ms pre-process, 28.9ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 5 trucks, 7 traffic lights, 28.6ms\n",
            "Speed: 1.1ms pre-process, 28.6ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 6 trucks, 10 traffic lights, 27.9ms\n",
            "Speed: 1.2ms pre-process, 27.9ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 6 trucks, 9 traffic lights, 27.9ms\n",
            "Speed: 1.0ms pre-process, 27.9ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 5 trucks, 8 traffic lights, 27.7ms\n",
            "Speed: 1.1ms pre-process, 27.7ms inference, 2.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 5 trucks, 8 traffic lights, 1 suitcase, 28.0ms\n",
            "Speed: 2.4ms pre-process, 28.0ms inference, 2.1ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 6 trucks, 9 traffic lights, 30.6ms\n",
            "Speed: 1.0ms pre-process, 30.6ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 6 trucks, 9 traffic lights, 27.9ms\n",
            "Speed: 1.1ms pre-process, 27.9ms inference, 2.1ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 48 cars, 5 trucks, 8 traffic lights, 27.7ms\n",
            "Speed: 1.0ms pre-process, 27.7ms inference, 2.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 7 trucks, 7 traffic lights, 27.8ms\n",
            "Speed: 1.1ms pre-process, 27.8ms inference, 2.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 7 trucks, 7 traffic lights, 27.8ms\n",
            "Speed: 1.1ms pre-process, 27.8ms inference, 2.3ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 39 cars, 6 trucks, 7 traffic lights, 39.8ms\n",
            "Speed: 11.9ms pre-process, 39.8ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 6 trucks, 6 traffic lights, 27.8ms\n",
            "Speed: 1.0ms pre-process, 27.8ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 38 cars, 6 trucks, 6 traffic lights, 32.0ms\n",
            "Speed: 1.1ms pre-process, 32.0ms inference, 2.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 6 trucks, 5 traffic lights, 29.6ms\n",
            "Speed: 2.5ms pre-process, 29.6ms inference, 2.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 6 trucks, 4 traffic lights, 38.2ms\n",
            "Speed: 1.0ms pre-process, 38.2ms inference, 25.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 39 cars, 6 trucks, 4 traffic lights, 41.4ms\n",
            "Speed: 1.1ms pre-process, 41.4ms inference, 2.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 8 trucks, 4 traffic lights, 36.0ms\n",
            "Speed: 1.1ms pre-process, 36.0ms inference, 2.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 50 cars, 8 trucks, 5 traffic lights, 45.7ms\n",
            "Speed: 6.1ms pre-process, 45.7ms inference, 2.3ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 8 trucks, 4 traffic lights, 34.3ms\n",
            "Speed: 1.1ms pre-process, 34.3ms inference, 11.1ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 38 cars, 7 trucks, 6 traffic lights, 33.5ms\n",
            "Speed: 2.2ms pre-process, 33.5ms inference, 5.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 8 trucks, 5 traffic lights, 53.8ms\n",
            "Speed: 16.9ms pre-process, 53.8ms inference, 2.1ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 8 trucks, 7 traffic lights, 30.6ms\n",
            "Speed: 1.1ms pre-process, 30.6ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 8 trucks, 6 traffic lights, 30.6ms\n",
            "Speed: 4.3ms pre-process, 30.6ms inference, 2.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 8 trucks, 7 traffic lights, 31.6ms\n",
            "Speed: 1.1ms pre-process, 31.6ms inference, 2.3ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 7 trucks, 7 traffic lights, 30.6ms\n",
            "Speed: 9.4ms pre-process, 30.6ms inference, 2.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 38 cars, 6 trucks, 8 traffic lights, 31.2ms\n",
            "Speed: 1.1ms pre-process, 31.2ms inference, 2.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 38 cars, 8 trucks, 5 traffic lights, 30.9ms\n",
            "Speed: 1.2ms pre-process, 30.9ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 6 trucks, 5 traffic lights, 30.5ms\n",
            "Speed: 1.1ms pre-process, 30.5ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 9 trucks, 5 traffic lights, 26.8ms\n",
            "Speed: 1.1ms pre-process, 26.8ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 8 trucks, 6 traffic lights, 26.7ms\n",
            "Speed: 1.0ms pre-process, 26.7ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 49 cars, 9 trucks, 7 traffic lights, 27.0ms\n",
            "Speed: 1.1ms pre-process, 27.0ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 48 cars, 9 trucks, 8 traffic lights, 27.0ms\n",
            "Speed: 1.1ms pre-process, 27.0ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 5 trucks, 7 traffic lights, 26.8ms\n",
            "Speed: 1.0ms pre-process, 26.8ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 6 trucks, 7 traffic lights, 26.9ms\n",
            "Speed: 1.1ms pre-process, 26.9ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 6 trucks, 6 traffic lights, 26.8ms\n",
            "Speed: 1.0ms pre-process, 26.8ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 6 trucks, 7 traffic lights, 26.9ms\n",
            "Speed: 1.0ms pre-process, 26.9ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 1 bus, 5 trucks, 7 traffic lights, 27.0ms\n",
            "Speed: 1.1ms pre-process, 27.0ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 1 bus, 6 trucks, 7 traffic lights, 26.8ms\n",
            "Speed: 1.1ms pre-process, 26.8ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 7 trucks, 7 traffic lights, 26.9ms\n",
            "Speed: 1.0ms pre-process, 26.9ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 1 bus, 6 trucks, 7 traffic lights, 26.1ms\n",
            "Speed: 1.0ms pre-process, 26.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 39 cars, 2 buss, 5 trucks, 7 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 39 cars, 4 trucks, 6 traffic lights, 25.9ms\n",
            "Speed: 1.1ms pre-process, 25.9ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 38 cars, 4 trucks, 6 traffic lights, 29.2ms\n",
            "Speed: 1.1ms pre-process, 29.2ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 37 cars, 3 trucks, 8 traffic lights, 26.4ms\n",
            "Speed: 1.0ms pre-process, 26.4ms inference, 3.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 36 cars, 5 trucks, 6 traffic lights, 26.7ms\n",
            "Speed: 1.1ms pre-process, 26.7ms inference, 2.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 3 trucks, 7 traffic lights, 26.1ms\n",
            "Speed: 1.0ms pre-process, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 37 cars, 4 trucks, 8 traffic lights, 26.2ms\n",
            "Speed: 1.1ms pre-process, 26.2ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 36 cars, 4 trucks, 8 traffic lights, 25.9ms\n",
            "Speed: 1.1ms pre-process, 25.9ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 37 cars, 3 trucks, 8 traffic lights, 25.9ms\n",
            "Speed: 1.1ms pre-process, 25.9ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 4 trucks, 7 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 39 cars, 4 trucks, 7 traffic lights, 26.1ms\n",
            "Speed: 1.0ms pre-process, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 38 cars, 3 trucks, 8 traffic lights, 25.9ms\n",
            "Speed: 1.1ms pre-process, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 39 cars, 6 trucks, 8 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 6 trucks, 8 traffic lights, 26.1ms\n",
            "Speed: 0.9ms pre-process, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 7 trucks, 7 traffic lights, 26.0ms\n",
            "Speed: 1.7ms pre-process, 26.0ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 6 trucks, 7 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 6 trucks, 7 traffic lights, 26.3ms\n",
            "Speed: 1.1ms pre-process, 26.3ms inference, 3.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 6 trucks, 7 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 35 cars, 4 trucks, 8 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 4 trucks, 8 traffic lights, 26.0ms\n",
            "Speed: 1.1ms pre-process, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 5 trucks, 7 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 5 trucks, 7 traffic lights, 26.0ms\n",
            "Speed: 1.8ms pre-process, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 5 trucks, 6 traffic lights, 26.0ms\n",
            "Speed: 1.0ms pre-process, 26.0ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 48 cars, 5 trucks, 6 traffic lights, 26.0ms\n",
            "Speed: 1.1ms pre-process, 26.0ms inference, 3.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 49 cars, 7 trucks, 6 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 49 cars, 6 trucks, 6 traffic lights, 26.2ms\n",
            "Speed: 1.1ms pre-process, 26.2ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 49 cars, 6 trucks, 7 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 6 trucks, 8 traffic lights, 26.0ms\n",
            "Speed: 1.2ms pre-process, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 5 trucks, 8 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 5 trucks, 8 traffic lights, 26.1ms\n",
            "Speed: 1.2ms pre-process, 26.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 6 trucks, 8 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 49 cars, 9 trucks, 8 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 5 trucks, 7 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 5 trucks, 8 traffic lights, 26.0ms\n",
            "Speed: 1.1ms pre-process, 26.0ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 49 cars, 4 trucks, 7 traffic lights, 26.0ms\n",
            "Speed: 1.1ms pre-process, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 4 trucks, 5 traffic lights, 25.9ms\n",
            "Speed: 1.1ms pre-process, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 52 cars, 3 trucks, 6 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 3 trucks, 6 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 5 trucks, 7 traffic lights, 25.9ms\n",
            "Speed: 2.9ms pre-process, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 4 trucks, 5 traffic lights, 26.3ms\n",
            "Speed: 0.9ms pre-process, 26.3ms inference, 2.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 4 trucks, 6 traffic lights, 26.1ms\n",
            "Speed: 0.9ms pre-process, 26.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 52 cars, 4 trucks, 8 traffic lights, 27.0ms\n",
            "Speed: 1.0ms pre-process, 27.0ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 3 trucks, 6 traffic lights, 26.3ms\n",
            "Speed: 1.0ms pre-process, 26.3ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 43 cars, 4 trucks, 6 traffic lights, 26.4ms\n",
            "Speed: 1.3ms pre-process, 26.4ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 49 cars, 4 trucks, 8 traffic lights, 26.3ms\n",
            "Speed: 1.1ms pre-process, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 45 cars, 5 trucks, 8 traffic lights, 26.6ms\n",
            "Speed: 1.1ms pre-process, 26.6ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 50 cars, 6 trucks, 9 traffic lights, 26.7ms\n",
            "Speed: 3.5ms pre-process, 26.7ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 50 cars, 5 trucks, 10 traffic lights, 29.4ms\n",
            "Speed: 1.2ms pre-process, 29.4ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 5 trucks, 9 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 50 cars, 3 trucks, 9 traffic lights, 26.0ms\n",
            "Speed: 1.2ms pre-process, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 51 cars, 5 trucks, 6 traffic lights, 26.1ms\n",
            "Speed: 1.0ms pre-process, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 5 trucks, 6 traffic lights, 26.3ms\n",
            "Speed: 1.0ms pre-process, 26.3ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 7 trucks, 7 traffic lights, 26.2ms\n",
            "Speed: 1.0ms pre-process, 26.2ms inference, 2.1ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 51 cars, 7 trucks, 8 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 51 cars, 5 trucks, 7 traffic lights, 1 suitcase, 26.0ms\n",
            "Speed: 1.0ms pre-process, 26.0ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 54 cars, 6 trucks, 8 traffic lights, 26.1ms\n",
            "Speed: 1.0ms pre-process, 26.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 57 cars, 7 trucks, 7 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 53 cars, 6 trucks, 6 traffic lights, 26.2ms\n",
            "Speed: 1.0ms pre-process, 26.2ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 51 cars, 6 trucks, 7 traffic lights, 26.1ms\n",
            "Speed: 1.2ms pre-process, 26.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 6 trucks, 6 traffic lights, 25.9ms\n",
            "Speed: 1.1ms pre-process, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 53 cars, 6 trucks, 7 traffic lights, 26.0ms\n",
            "Speed: 1.1ms pre-process, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 57 cars, 5 trucks, 5 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 53 cars, 5 trucks, 7 traffic lights, 26.0ms\n",
            "Speed: 1.1ms pre-process, 26.0ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 56 cars, 5 trucks, 5 traffic lights, 26.0ms\n",
            "Speed: 1.0ms pre-process, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 53 cars, 5 trucks, 6 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 52 cars, 6 trucks, 5 traffic lights, 26.1ms\n",
            "Speed: 1.3ms pre-process, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 54 cars, 5 trucks, 7 traffic lights, 26.1ms\n",
            "Speed: 1.0ms pre-process, 26.1ms inference, 3.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 49 cars, 7 trucks, 8 traffic lights, 26.1ms\n",
            "Speed: 1.5ms pre-process, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 53 cars, 6 trucks, 8 traffic lights, 26.2ms\n",
            "Speed: 1.0ms pre-process, 26.2ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 48 cars, 4 trucks, 8 traffic lights, 26.2ms\n",
            "Speed: 1.1ms pre-process, 26.2ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 5 trucks, 7 traffic lights, 26.1ms\n",
            "Speed: 1.0ms pre-process, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 49 cars, 5 trucks, 7 traffic lights, 26.1ms\n",
            "Speed: 1.0ms pre-process, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 50 cars, 3 trucks, 9 traffic lights, 26.2ms\n",
            "Speed: 1.1ms pre-process, 26.2ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 45 cars, 3 trucks, 11 traffic lights, 26.3ms\n",
            "Speed: 1.0ms pre-process, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 55 cars, 3 trucks, 9 traffic lights, 26.6ms\n",
            "Speed: 1.1ms pre-process, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 48 cars, 1 bus, 4 trucks, 8 traffic lights, 26.6ms\n",
            "Speed: 1.2ms pre-process, 26.6ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 4 trucks, 5 traffic lights, 30.0ms\n",
            "Speed: 1.1ms pre-process, 30.0ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 54 cars, 3 trucks, 6 traffic lights, 26.5ms\n",
            "Speed: 1.0ms pre-process, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 53 cars, 4 trucks, 7 traffic lights, 26.6ms\n",
            "Speed: 1.6ms pre-process, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 48 cars, 4 trucks, 5 traffic lights, 26.4ms\n",
            "Speed: 1.0ms pre-process, 26.4ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 4 trucks, 6 traffic lights, 26.8ms\n",
            "Speed: 1.0ms pre-process, 26.8ms inference, 2.1ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 39 cars, 3 trucks, 5 traffic lights, 26.6ms\n",
            "Speed: 1.1ms pre-process, 26.6ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 3 trucks, 6 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 3 trucks, 6 traffic lights, 26.2ms\n",
            "Speed: 1.1ms pre-process, 26.2ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 3 trucks, 6 traffic lights, 26.0ms\n",
            "Speed: 1.1ms pre-process, 26.0ms inference, 2.3ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 48 cars, 4 trucks, 7 traffic lights, 26.1ms\n",
            "Speed: 1.0ms pre-process, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 48 cars, 4 trucks, 7 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 3 trucks, 6 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 4 trucks, 6 traffic lights, 28.0ms\n",
            "Speed: 1.3ms pre-process, 28.0ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 45 cars, 4 trucks, 7 traffic lights, 28.3ms\n",
            "Speed: 1.2ms pre-process, 28.3ms inference, 2.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 45 cars, 5 trucks, 6 traffic lights, 26.0ms\n",
            "Speed: 1.1ms pre-process, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 44 cars, 5 trucks, 6 traffic lights, 26.1ms\n",
            "Speed: 1.4ms pre-process, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 41 cars, 4 trucks, 6 traffic lights, 26.0ms\n",
            "Speed: 1.2ms pre-process, 26.0ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 40 cars, 4 trucks, 7 traffic lights, 26.0ms\n",
            "Speed: 1.1ms pre-process, 26.0ms inference, 2.3ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 35 cars, 4 trucks, 7 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 39 cars, 5 trucks, 7 traffic lights, 26.2ms\n",
            "Speed: 1.1ms pre-process, 26.2ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 42 cars, 5 trucks, 6 traffic lights, 26.8ms\n",
            "Speed: 1.0ms pre-process, 26.8ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 47 cars, 4 trucks, 6 traffic lights, 26.1ms\n",
            "Speed: 1.0ms pre-process, 26.1ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 48 cars, 5 trucks, 7 traffic lights, 26.1ms\n",
            "Speed: 1.0ms pre-process, 26.1ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 48 cars, 4 trucks, 6 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 38 cars, 3 trucks, 8 traffic lights, 26.0ms\n",
            "Speed: 1.0ms pre-process, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 3 trucks, 8 traffic lights, 26.2ms\n",
            "Speed: 1.3ms pre-process, 26.2ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 43 cars, 3 trucks, 7 traffic lights, 26.2ms\n",
            "Speed: 1.1ms pre-process, 26.2ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 46 cars, 2 trucks, 7 traffic lights, 26.2ms\n",
            "Speed: 1.1ms pre-process, 26.2ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 38 cars, 1 bus, 6 trucks, 7 traffic lights, 26.1ms\n",
            "Speed: 2.1ms pre-process, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 44 cars, 5 trucks, 7 traffic lights, 26.0ms\n",
            "Speed: 1.1ms pre-process, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 44 cars, 4 trucks, 7 traffic lights, 26.2ms\n",
            "Speed: 1.2ms pre-process, 26.2ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 43 cars, 4 trucks, 8 traffic lights, 26.1ms\n",
            "Speed: 1.2ms pre-process, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 4 trucks, 6 traffic lights, 28.0ms\n",
            "Speed: 1.1ms pre-process, 28.0ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 43 cars, 4 trucks, 6 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 37 cars, 5 trucks, 6 traffic lights, 26.3ms\n",
            "Speed: 1.1ms pre-process, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 1 bus, 4 trucks, 7 traffic lights, 26.1ms\n",
            "Speed: 1.0ms pre-process, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 1 person, 37 cars, 4 trucks, 8 traffic lights, 26.3ms\n",
            "Speed: 1.1ms pre-process, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 6 trucks, 8 traffic lights, 26.5ms\n",
            "Speed: 1.0ms pre-process, 26.5ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 36 cars, 5 trucks, 8 traffic lights, 26.5ms\n",
            "Speed: 1.0ms pre-process, 26.5ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 4 trucks, 8 traffic lights, 26.5ms\n",
            "Speed: 1.0ms pre-process, 26.5ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 1 bus, 3 trucks, 7 traffic lights, 26.4ms\n",
            "Speed: 1.3ms pre-process, 26.4ms inference, 2.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 1 bus, 4 trucks, 7 traffic lights, 26.4ms\n",
            "Speed: 1.1ms pre-process, 26.4ms inference, 2.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 5 trucks, 8 traffic lights, 26.0ms\n",
            "Speed: 1.2ms pre-process, 26.0ms inference, 2.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 5 trucks, 8 traffic lights, 27.1ms\n",
            "Speed: 1.1ms pre-process, 27.1ms inference, 2.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 7 trucks, 7 traffic lights, 26.0ms\n",
            "Speed: 4.0ms pre-process, 26.0ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 7 trucks, 7 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 5 trucks, 7 traffic lights, 26.0ms\n",
            "Speed: 1.3ms pre-process, 26.0ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 37 cars, 5 trucks, 7 traffic lights, 28.5ms\n",
            "Speed: 2.5ms pre-process, 28.5ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 7 trucks, 6 traffic lights, 26.0ms\n",
            "Speed: 1.0ms pre-process, 26.0ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 7 trucks, 7 traffic lights, 30.8ms\n",
            "Speed: 1.0ms pre-process, 30.8ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 37 cars, 6 trucks, 7 traffic lights, 25.9ms\n",
            "Speed: 1.1ms pre-process, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 37 cars, 7 trucks, 7 traffic lights, 26.0ms\n",
            "Speed: 1.0ms pre-process, 26.0ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 7 trucks, 7 traffic lights, 31.1ms\n",
            "Speed: 1.1ms pre-process, 31.1ms inference, 2.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 5 trucks, 6 traffic lights, 26.0ms\n",
            "Speed: 1.1ms pre-process, 26.0ms inference, 2.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 6 trucks, 8 traffic lights, 32.0ms\n",
            "Speed: 1.1ms pre-process, 32.0ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 6 trucks, 8 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 48 cars, 6 trucks, 9 traffic lights, 26.1ms\n",
            "Speed: 1.0ms pre-process, 26.1ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 5 trucks, 9 traffic lights, 26.0ms\n",
            "Speed: 1.0ms pre-process, 26.0ms inference, 5.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 4 trucks, 9 traffic lights, 26.0ms\n",
            "Speed: 6.1ms pre-process, 26.0ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 6 trucks, 8 traffic lights, 28.0ms\n",
            "Speed: 1.1ms pre-process, 28.0ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 4 trucks, 7 traffic lights, 26.5ms\n",
            "Speed: 1.1ms pre-process, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 39 cars, 7 trucks, 6 traffic lights, 25.9ms\n",
            "Speed: 1.1ms pre-process, 25.9ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 5 trucks, 7 traffic lights, 29.4ms\n",
            "Speed: 1.2ms pre-process, 29.4ms inference, 3.1ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 4 trucks, 7 traffic lights, 28.2ms\n",
            "Speed: 1.1ms pre-process, 28.2ms inference, 2.1ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 4 trucks, 7 traffic lights, 28.8ms\n",
            "Speed: 1.1ms pre-process, 28.8ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 6 trucks, 7 traffic lights, 28.8ms\n",
            "Speed: 1.0ms pre-process, 28.8ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 5 trucks, 7 traffic lights, 29.7ms\n",
            "Speed: 1.1ms pre-process, 29.7ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 4 trucks, 7 traffic lights, 26.3ms\n",
            "Speed: 1.1ms pre-process, 26.3ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 7 trucks, 8 traffic lights, 26.4ms\n",
            "Speed: 1.1ms pre-process, 26.4ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 36 cars, 5 trucks, 7 traffic lights, 26.4ms\n",
            "Speed: 1.0ms pre-process, 26.4ms inference, 2.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 34 cars, 7 trucks, 7 traffic lights, 26.4ms\n",
            "Speed: 1.3ms pre-process, 26.4ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 1 bus, 5 trucks, 7 traffic lights, 29.7ms\n",
            "Speed: 1.1ms pre-process, 29.7ms inference, 2.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 39 cars, 6 trucks, 6 traffic lights, 26.3ms\n",
            "Speed: 1.0ms pre-process, 26.3ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 36 cars, 5 trucks, 7 traffic lights, 26.5ms\n",
            "Speed: 1.2ms pre-process, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 34 cars, 5 trucks, 7 traffic lights, 26.5ms\n",
            "Speed: 1.0ms pre-process, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 37 cars, 5 trucks, 8 traffic lights, 26.6ms\n",
            "Speed: 1.1ms pre-process, 26.6ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 35 cars, 5 trucks, 8 traffic lights, 27.1ms\n",
            "Speed: 1.1ms pre-process, 27.1ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 33 cars, 6 trucks, 7 traffic lights, 26.4ms\n",
            "Speed: 1.0ms pre-process, 26.4ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 36 cars, 6 trucks, 7 traffic lights, 26.5ms\n",
            "Speed: 1.0ms pre-process, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 28 cars, 6 trucks, 7 traffic lights, 26.4ms\n",
            "Speed: 1.0ms pre-process, 26.4ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 35 cars, 6 trucks, 6 traffic lights, 26.5ms\n",
            "Speed: 1.0ms pre-process, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 7 trucks, 6 traffic lights, 27.6ms\n",
            "Speed: 1.0ms pre-process, 27.6ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 37 cars, 5 trucks, 6 traffic lights, 26.5ms\n",
            "Speed: 1.0ms pre-process, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 5 trucks, 6 traffic lights, 26.4ms\n",
            "Speed: 1.1ms pre-process, 26.4ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 38 cars, 6 trucks, 7 traffic lights, 26.4ms\n",
            "Speed: 7.0ms pre-process, 26.4ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 34 cars, 6 trucks, 7 traffic lights, 1 refrigerator, 26.4ms\n",
            "Speed: 1.0ms pre-process, 26.4ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 38 cars, 5 trucks, 6 traffic lights, 1 refrigerator, 31.8ms\n",
            "Speed: 1.1ms pre-process, 31.8ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 5 trucks, 6 traffic lights, 27.1ms\n",
            "Speed: 1.0ms pre-process, 27.1ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 39 cars, 6 trucks, 5 traffic lights, 28.3ms\n",
            "Speed: 1.1ms pre-process, 28.3ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 37 cars, 5 trucks, 7 traffic lights, 28.2ms\n",
            "Speed: 2.1ms pre-process, 28.2ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 36 cars, 6 trucks, 8 traffic lights, 28.8ms\n",
            "Speed: 1.1ms pre-process, 28.8ms inference, 3.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 5 trucks, 6 traffic lights, 29.1ms\n",
            "Speed: 1.0ms pre-process, 29.1ms inference, 2.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 38 cars, 5 trucks, 6 traffic lights, 29.4ms\n",
            "Speed: 1.1ms pre-process, 29.4ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 6 trucks, 6 traffic lights, 29.3ms\n",
            "Speed: 1.0ms pre-process, 29.3ms inference, 2.1ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 38 cars, 5 trucks, 5 traffic lights, 29.3ms\n",
            "Speed: 1.1ms pre-process, 29.3ms inference, 2.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 35 cars, 5 trucks, 4 traffic lights, 30.0ms\n",
            "Speed: 1.1ms pre-process, 30.0ms inference, 2.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 37 cars, 6 trucks, 6 traffic lights, 33.0ms\n",
            "Speed: 1.1ms pre-process, 33.0ms inference, 2.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 40 cars, 5 trucks, 7 traffic lights, 30.0ms\n",
            "Speed: 1.2ms pre-process, 30.0ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 36 cars, 5 trucks, 7 traffic lights, 30.6ms\n",
            "Speed: 1.1ms pre-process, 30.6ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 3 trucks, 7 traffic lights, 30.5ms\n",
            "Speed: 1.0ms pre-process, 30.5ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 37 cars, 6 trucks, 6 traffic lights, 30.6ms\n",
            "Speed: 1.1ms pre-process, 30.6ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 38 cars, 5 trucks, 7 traffic lights, 1 microwave, 1 refrigerator, 28.8ms\n",
            "Speed: 1.1ms pre-process, 28.8ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 6 trucks, 7 traffic lights, 1 refrigerator, 28.9ms\n",
            "Speed: 1.1ms pre-process, 28.9ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 39 cars, 4 trucks, 7 traffic lights, 1 refrigerator, 28.8ms\n",
            "Speed: 1.2ms pre-process, 28.8ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 4 trucks, 6 traffic lights, 26.5ms\n",
            "Speed: 1.1ms pre-process, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 42 cars, 4 trucks, 5 traffic lights, 26.5ms\n",
            "Speed: 1.1ms pre-process, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 43 cars, 4 trucks, 5 traffic lights, 26.5ms\n",
            "Speed: 1.1ms pre-process, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 4 trucks, 5 traffic lights, 26.4ms\n",
            "Speed: 1.0ms pre-process, 26.4ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 4 trucks, 7 traffic lights, 26.5ms\n",
            "Speed: 1.0ms pre-process, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 41 cars, 4 trucks, 6 traffic lights, 26.6ms\n",
            "Speed: 1.1ms pre-process, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 48 cars, 3 trucks, 6 traffic lights, 26.4ms\n",
            "Speed: 1.1ms pre-process, 26.4ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 51 cars, 3 trucks, 5 traffic lights, 26.6ms\n",
            "Speed: 1.1ms pre-process, 26.6ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 52 cars, 3 trucks, 6 traffic lights, 26.1ms\n",
            "Speed: 1.1ms pre-process, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 3 trucks, 7 traffic lights, 26.2ms\n",
            "Speed: 1.1ms pre-process, 26.2ms inference, 1.7ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 49 cars, 3 trucks, 6 traffic lights, 26.2ms\n",
            "Speed: 1.1ms pre-process, 26.2ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 46 cars, 3 trucks, 6 traffic lights, 26.4ms\n",
            "Speed: 1.1ms pre-process, 26.4ms inference, 2.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 45 cars, 3 trucks, 5 traffic lights, 25.9ms\n",
            "Speed: 1.1ms pre-process, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 4 trucks, 5 traffic lights, 26.2ms\n",
            "Speed: 1.1ms pre-process, 26.2ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 47 cars, 4 trucks, 6 traffic lights, 26.0ms\n",
            "Speed: 1.5ms pre-process, 26.0ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "\n",
            "0: 736x1280 44 cars, 5 trucks, 5 traffic lights, 25.9ms\n",
            "Speed: 1.0ms pre-process, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n"
          ]
        }
      ],
      "source": [
        "sv.process_video(source_path=VIDEO, target_path=f\"result.mp4\", callback=process_frame)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "yolo8",
      "language": "python",
      "name": "yolo8"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "98baf92f097a0eb868dff489052d41c908751db3fecc1d330a3aa307b20d5236"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2aa4be84b8bc4a4bb59a626a81e2acdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e05518423ee14d34886fcbdc80f9bc4b",
            "max": 22573363,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5adc7616c0f14a27b299bc75a91acdb8",
            "value": 22573363
          }
        },
        "343a221a027c4a33b5e9c081bc81f7c2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5684c82e404045109e27167ca4817eaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e526d9b1f45445268ddffd6fc3e8133a",
              "IPY_MODEL_2aa4be84b8bc4a4bb59a626a81e2acdc",
              "IPY_MODEL_d7fd42066585465a93f289f55504bbd2"
            ],
            "layout": "IPY_MODEL_343a221a027c4a33b5e9c081bc81f7c2"
          }
        },
        "5adc7616c0f14a27b299bc75a91acdb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a45df22c143b49bb96b077f0797cee90": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0d5858fae274036a20a98e5a401b7be": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d75030e954e54dec8be0773d54fef863": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7fd42066585465a93f289f55504bbd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0d5858fae274036a20a98e5a401b7be",
            "placeholder": "​",
            "style": "IPY_MODEL_d75030e954e54dec8be0773d54fef863",
            "value": " 21.5M/21.5M [00:00&lt;00:00, 45.2MB/s]"
          }
        },
        "e05518423ee14d34886fcbdc80f9bc4b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3df80f7fe424d9ebeffeb3ec83780b6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e526d9b1f45445268ddffd6fc3e8133a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3df80f7fe424d9ebeffeb3ec83780b6",
            "placeholder": "​",
            "style": "IPY_MODEL_a45df22c143b49bb96b077f0797cee90",
            "value": "100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
